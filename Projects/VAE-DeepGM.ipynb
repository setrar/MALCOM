{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d76aa69c-618c-4e01-a223-f88b1ebd6dce",
   "metadata": {},
   "source": [
    "### Deep Generative Models\n",
    "\n",
    "A deep generative model is a type of machine learning model designed to generate new data samples that resemble a given dataset. These models learn the underlying distribution of the data and can then produce new instances that have similar statistical properties. They are particularly useful for tasks such as data augmentation, unsupervised learning, and anomaly detection.\n",
    "\n",
    "### Examples of Deep Generative Models\n",
    "\n",
    "1. **Variational Autoencoders (VAEs)**\n",
    "2. **Generative Adversarial Networks (GANs)**\n",
    "3. **Autoregressive Models (e.g., PixelCNN, WaveNet)**\n",
    "\n",
    "### Example: Variational Autoencoder (VAE) in Julia using Flux\n",
    "\n",
    "Below is an example implementation of a Variational Autoencoder (VAE) in Julia using the Flux library.\n",
    "\n",
    "#### Step 1: Setup Julia and Install Dependencies\n",
    "\n",
    "Ensure you have Julia installed and the necessary packages:\n",
    "\n",
    "```julia\n",
    "using Pkg\n",
    "Pkg.add(\"Flux\")\n",
    "Pkg.add(\"Distributions\")\n",
    "Pkg.add(\"Plots\")\n",
    "```\n",
    "\n",
    "#### Step 2: Implementing the VAE\n",
    "\n",
    "Here's a complete implementation of a simple VAE:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cae632f9-3fd3-46e7-83a8-e0e621f9ef13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mLayer with Float32 parameters got Float64 input.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  The input will be converted, but any earlier layers may be very slow.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  layer = Dense(784 => 512, relu)  \u001b[90m# 401_920 parameters\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  summary(x) = \"784×128 Matrix{Float64}\"\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Flux ~/.julia/packages/Flux/CUn7U/src/layers/stateless.jl:60\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed\n",
      "Epoch 2 completed\n",
      "Epoch 3 completed\n",
      "Epoch 4 completed\n",
      "Epoch 5 completed\n",
      "Epoch 6 completed\n",
      "Epoch 7 completed\n",
      "Epoch 8 completed\n",
      "Epoch 9 completed\n",
      "Epoch 10 completed\n"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using Flux: Chain, Dense, Conv, relu, sigmoid, train!, params\n",
    "using Distributions\n",
    "using Plots\n",
    "\n",
    "# Define the encoder and decoder networks\n",
    "latent_dim = 2\n",
    "\n",
    "encoder = Chain(\n",
    "    Dense(28*28, 512, relu),\n",
    "    Dense(512, 256, relu),\n",
    "    Dense(256, 2 * latent_dim)  # Outputs mean and log-variance\n",
    ")\n",
    "\n",
    "decoder = Chain(\n",
    "    Dense(latent_dim, 256, relu),\n",
    "    Dense(256, 512, relu),\n",
    "    Dense(512, 28*28, sigmoid)\n",
    ")\n",
    "\n",
    "# Reparameterization trick\n",
    "function reparameterize(mu, logvar)\n",
    "    epsilon = randn(Float32, size(mu))\n",
    "    return mu .+ exp.(0.5f0 .* logvar) .* epsilon\n",
    "end\n",
    "\n",
    "# VAE forward pass\n",
    "function vae(x)\n",
    "    q = encoder(x)\n",
    "    mu = q[1:latent_dim, :]\n",
    "    logvar = q[latent_dim+1:end, :]\n",
    "    z = reparameterize(mu, logvar)\n",
    "    x̂ = decoder(z)\n",
    "    return x̂, mu, logvar\n",
    "end\n",
    "\n",
    "# Loss function\n",
    "function loss(x)\n",
    "    x̂, mu, logvar = vae(x)\n",
    "    reconstruction_loss = Flux.Losses.binarycrossentropy(x̂, x)\n",
    "    kl_divergence = -0.5f0 * sum(1 .+ logvar .- mu.^2 .- exp.(logvar))\n",
    "    return reconstruction_loss + kl_divergence\n",
    "end\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "using MLDatasets\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_data = MLDatasets.MNIST(:train)\n",
    "X_train = Float32.(reshape(train_data.features, 28*28, :)) ./ 255.0  # Normalize to [0, 1]\n",
    "\n",
    "# Training\n",
    "opt = ADAM()\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "for epoch in 1:epochs\n",
    "    for i in 1:batch_size:size(X_train, 2)\n",
    "        x = X_train[:, i:min(i + batch_size - 1, end)]\n",
    "        gs = Flux.gradient(() -> loss(x), params(encoder, decoder))\n",
    "        Flux.update!(opt, params(encoder, decoder), gs)\n",
    "    end\n",
    "    println(\"Epoch $epoch completed\")\n",
    "end\n",
    "\n",
    "# Generate new samples\n",
    "n_samples = 10\n",
    "z = randn(Float32, latent_dim, n_samples)\n",
    "generated_images = decoder(z)\n",
    "\n",
    "# Plotting generated images\n",
    "for i in 1:n_samples\n",
    "    img = reshape(generated_images[:, i], 28, 28)\n",
    "    heatmap(img, axis=false, title=\"Generated Image $i\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee34bb-8681-4e09-9cae-9b22b75a2f09",
   "metadata": {},
   "source": [
    "\n",
    "### Explanation\n",
    "\n",
    "1. **Encoder and Decoder Networks**:\n",
    "    - The encoder network compresses the input image into a lower-dimensional latent space, outputting the mean (`mu`) and log-variance (`logvar`).\n",
    "    - The decoder network reconstructs the input image from the latent space.\n",
    "\n",
    "2. **Reparameterization Trick**:\n",
    "    - This allows backpropagation through the stochastic latent variable by sampling `z` using the mean and log-variance.\n",
    "\n",
    "3. **Loss Function**:\n",
    "    - The loss function consists of two parts: reconstruction loss (how well the input image is reconstructed) and KL divergence (how close the learned latent space distribution is to a normal distribution).\n",
    "\n",
    "4. **Training**:\n",
    "    - The training loop uses the ADAM optimizer to update the encoder and decoder parameters based on the loss computed from the training data.\n",
    "\n",
    "5. **Generating New Samples**:\n",
    "    - After training, new samples are generated by sampling from the latent space and passing these samples through the decoder.\n",
    "\n",
    "6. **Plotting**:\n",
    "    - Generated images are visualized using heatmaps.\n",
    "\n",
    "This implementation shows how to create a simple VAE in Julia using the Flux library, enabling the generation of new, similar data from the learned distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bda16b-bb88-4846-9086-b372e9dddc3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
