{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be4e4802-d8dd-4f20-a0a6-6befb3dc0bc1",
   "metadata": {},
   "source": [
    "Certainly! Let's create an example in Julia where we calculate and maximize mutual information between two random variables. In this example, we'll use synthetic data to demonstrate how to compute mutual information and attempt to increase it by manipulating the data slightly.\n",
    "\n",
    "### Example Overview:\n",
    "1. **Generate Synthetic Data**: We'll create two random variables, `X` and `Y`. Initially, `Y` will be a noisy linear function of `X`.\n",
    "2. **Calculate Mutual Information**: We'll compute the mutual information between `X` and `Y` using a histogram-based method.\n",
    "3. **Modify Data to Maximize Mutual Information**: We'll adjust `Y` to reduce the noise and see how this affects the mutual information.\n",
    "\n",
    "### Prerequisites:\n",
    "You will need the Julia packages `Random`, `Distributions`, and `InformationMeasures`. If you don't have `InformationMeasures` installed, you can install it via Julia's package manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8347b2d7-98c5-419d-bb7e-2c7df3fadb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary packages\n",
    "using Random\n",
    "using Distributions\n",
    "using StatsBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "494c617c-3704-4ca9-b2ad-b6283f37a1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mutualinfo (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mutualinfo(pₓᵧ, pₓ, pᵧ)\n",
    "    mutual_info = sum(\n",
    "        pₓᵧ[i, j] > 0 ? pₓᵧ[i, j] * log(pₓᵧ[i, j] / (pₓ[i] * pᵧ[j])) : 0\n",
    "        for i in 1:size(pₓᵧ, 1), j in 1:size(pₓᵧ, 2)\n",
    "    )\n",
    "\n",
    "    return mutual_info\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e9d642-731e-4e55-9b04-fb668c40c417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculate_MI (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to calculate mutual information\n",
    "function calculate_MI(x, y, bins)\n",
    "    joint_histogram = fit(Histogram, (x, y), nbins=(10, 10)).weights\n",
    "    x_hist = sum(joint_histogram, dims=2) ./ length(x)\n",
    "    y_hist = sum(joint_histogram, dims=1) ./ length(y)\n",
    "    joint_hist = joint_histogram ./ length(x)\n",
    "\n",
    "    # Calculate mutual information\n",
    "    mi = mutualinfo(joint_hist, x_hist, y_hist)\n",
    "    return mi\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e9b3fe0-ae67-4849-b0d1-c4108f722cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Mutual Information: 1.003762634653383\n",
      "Updated Mutual Information with Reduced Noise: 1.135084013142174\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "Random.seed!(42)  # Seed for reproducibility\n",
    "X = rand(Normal(0, 1), 1000)\n",
    "noise = rand(Normal(0, 0.5), 1000)\n",
    "Y = 3 * X + noise  # Y is a noisy linear function of X\n",
    "\n",
    "# Calculate mutual information with initial data\n",
    "initial_MI = calculate_MI(X, Y, 20)\n",
    "println(\"Initial Mutual Information: $initial_MI\")\n",
    "\n",
    "# Reduce noise in Y and recalculate mutual information\n",
    "Y_reduced_noise = 3 * X + rand(Normal(0, 0.1), 1000)\n",
    "updated_MI = calculate_MI(X, Y_reduced_noise, 20)\n",
    "println(\"Updated Mutual Information with Reduced Noise: $updated_MI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155c7859-91d2-4948-995d-b91d37a9f474",
   "metadata": {},
   "source": [
    "\n",
    "### Explanation:\n",
    "- We first create `X` and `Y`, where `Y` depends linearly on `X` but includes some noise.\n",
    "- The `calculate_MI` function calculates mutual information using histogram bins for both variables and their joint distribution.\n",
    "- We then reduce the noise in `Y` and recalculate the mutual information to see the effect of a clearer relationship between `X` and `Y`.\n",
    "\n",
    "This example shows a simple scenario where reducing noise directly increases the mutual information, thereby improving the predictability between `X` and `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb7ddd8-ba4e-4427-b7b5-352c1f5787c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
