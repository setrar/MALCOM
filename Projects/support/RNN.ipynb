{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84505f84-a9b0-4a30-b41b-51cd91ba2c8a",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08c4eab5-eb97-4325-8daf-688da0d20e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Statistics\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "using Random\n",
    "Random.seed!(42);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9b1dec-e090-4edc-a595-1a53ce51d3cd",
   "metadata": {},
   "source": [
    "### Simple Neural Network\n",
    "We will start by defining a simple neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28ecb980-f524-4508-9e19-4e20c736fa42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain(Dense(20 => 10, relu), Dense(10 => 5, relu), Dense(5 => 1))\n"
     ]
    }
   ],
   "source": [
    "# Define a simple feedforward neural network\n",
    "model = Chain(\n",
    "    Dense(20, 10, relu),\n",
    "    Dense(10, 5, relu),\n",
    "    Dense(5, 1)\n",
    ")\n",
    "\n",
    "# Display the model\n",
    "println(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9362a4-8158-46aa-9ec0-e0d31b9bbd69",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network (RNN)\n",
    "Next, we'll implement an RNN, which is crucial for time-series data and tasks involving memory, as discussed in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be3ecee4-6cc7-4774-b0f5-fa21eb9b0bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain(Recur(RNNCell(20 => 10, relu)), Dense(10 => 1))\n"
     ]
    }
   ],
   "source": [
    "# Define a simple RNN\n",
    "rnn_model = Chain(\n",
    "    RNN(20, 10, relu),\n",
    "    Dense(10, 1)\n",
    ")\n",
    "\n",
    "# Display the RNN model\n",
    "println(rnn_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180f37e4-6ee9-41a8-9057-d6e34b40decf",
   "metadata": {},
   "source": [
    "### Estimation and Optimization\n",
    "Now, let's perform a simple estimation and optimization task using the defined neural network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b71fb231-40e3-4540-92c3-b43ebc3f05d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss = 0.109690934\n",
      "Epoch 20: Loss = 0.106898755\n",
      "Epoch 30: Loss = 0.103969134\n",
      "Epoch 40: Loss = 0.10093229\n",
      "Epoch 50: Loss = 0.09859385\n",
      "Epoch 60: Loss = 0.09666082\n",
      "Epoch 70: Loss = 0.09477972\n",
      "Epoch 80: Loss = 0.093320996\n",
      "Epoch 90: Loss = 0.092067644\n",
      "Epoch 100: Loss = 0.09096549\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "X = rand(Float32, 20, 100)  # 100 samples of 20-dimensional input\n",
    "Y = rand(Float32, 1, 100)   # 100 samples of scalar output\n",
    "\n",
    "# Define loss function\n",
    "loss(x, y) = Flux.mse(rnn_model(x), y)\n",
    "\n",
    "# Define optimizer\n",
    "opt = Descent(0.01)\n",
    "\n",
    "# Train the model\n",
    "for epoch in 1:100\n",
    "    Flux.train!(loss, Flux.params(rnn_model), [(X, Y)], opt)\n",
    "    if epoch % 10 == 0\n",
    "        println(\"Epoch $epoch: Loss = \", loss(X, Y))\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa59f9f-0db1-44cb-b036-92ffc20938a5",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Finally, let's evaluate the model on some test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34c2bbd0-8ab2-4db0-a610-a446e363a85b",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "DimensionMismatch: arrays could not be broadcast to a common size; got a dimension with lengths 10 and 100",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch: arrays could not be broadcast to a common size; got a dimension with lengths 10 and 100",
      "",
      "Stacktrace:",
      "  [1] _bcs1",
      "    @ ./broadcast.jl:555 [inlined]",
      "  [2] _bcs (repeats 2 times)",
      "    @ ./broadcast.jl:549 [inlined]",
      "  [3] broadcast_shape",
      "    @ ./broadcast.jl:543 [inlined]",
      "  [4] combine_axes",
      "    @ ./broadcast.jl:524 [inlined]",
      "  [5] _axes",
      "    @ ./broadcast.jl:236 [inlined]",
      "  [6] axes",
      "    @ ./broadcast.jl:234 [inlined]",
      "  [7] combine_axes",
      "    @ ./broadcast.jl:524 [inlined]",
      "  [8] _axes",
      "    @ ./broadcast.jl:236 [inlined]",
      "  [9] axes",
      "    @ ./broadcast.jl:234 [inlined]",
      " [10] combine_axes(A::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{2}, Nothing, typeof(+), Tuple{Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{2}, Nothing, typeof(+), Tuple{Matrix{Float32}, Matrix{Float32}}}, Vector{Float32}}})",
      "    @ Base.Broadcast ./broadcast.jl:525",
      " [11] instantiate",
      "    @ ./broadcast.jl:306 [inlined]",
      " [12] materialize",
      "    @ ./broadcast.jl:903 [inlined]",
      " [13] (::Flux.RNNCell{typeof(relu), Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Matrix{Float32}})(h::Matrix{Float32}, x::SubArray{Float32, 2, Array{Float32, 3}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Int64}, true})",
      "    @ Flux ~/.julia/packages/Flux/Wz6D4/src/layers/recurrent.jl:207",
      " [14] Recur",
      "    @ ~/.julia/packages/Flux/Wz6D4/src/layers/recurrent.jl:134 [inlined]",
      " [15] #247",
      "    @ ./none:0 [inlined]",
      " [16] iterate",
      "    @ ./generator.jl:47 [inlined]",
      " [17] collect(itr::Base.Generator{Base.Generator{Base.OneTo{Int64}, Flux.var\"#239#241\"{Array{Float32, 3}, Tuple{Colon, Colon}}}, Flux.var\"#247#248\"{Flux.Recur{Flux.RNNCell{typeof(relu), Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Matrix{Float32}}, Matrix{Float32}}}})",
      "    @ Base ./array.jl:834",
      " [18] Recur",
      "    @ ~/.julia/packages/Flux/Wz6D4/src/layers/recurrent.jl:184 [inlined]",
      " [19] macro expansion",
      "    @ ~/.julia/packages/Flux/Wz6D4/src/layers/basic.jl:53 [inlined]",
      " [20] _applychain(layers::Tuple{Flux.Recur{Flux.RNNCell{typeof(relu), Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Matrix{Float32}}, Matrix{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}, x::Array{Float32, 3})",
      "    @ Flux ~/.julia/packages/Flux/Wz6D4/src/layers/basic.jl:53",
      " [21] (::Chain{Tuple{Flux.Recur{Flux.RNNCell{typeof(relu), Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Matrix{Float32}}, Matrix{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}})(x::Array{Float32, 3})",
      "    @ Flux ~/.julia/packages/Flux/Wz6D4/src/layers/basic.jl:51",
      " [22] top-level scope",
      "    @ In[12]:6"
     ]
    }
   ],
   "source": [
    "# Generate test data\n",
    "X_test = rand(Float32, 20, 10, 1)  # 10 samples of 20-dimensional input, reshaped to (20, 10, 1)\n",
    "Y_test = rand(Float32, 1, 10)      # 10 samples of scalar output, reshaped to (1, 10)\n",
    "\n",
    "# Make predictions\n",
    "predictions = rnn_model(X_test)\n",
    "\n",
    "# Calculate and print the test loss\n",
    "test_loss = loss(X_test, Y_test)\n",
    "println(\"Test Loss: \", test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9f2326f-9888-4e64-b2bc-0bf94b3e6b57",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `ibm_data` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `ibm_data` not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[13]:5"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5589ab-6123-4943-98a9-30ba6db24f26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
