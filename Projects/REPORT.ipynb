{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff01be6-0bd1-4909-9244-c8dda1c5deab",
   "metadata": {},
   "source": [
    "# Neural Estimation and Optimization of Directed Information Over Continuous Spaces\n",
    "\n",
    "Dor Tsur , Student Member, IEEE, Ziv Aharoni , Student Member, IEEE, Ziv Goldfeld , Member, IEEE, and Haim Permuter , Senior Member, IEEE\n",
    "\n",
    "##### ___Abstract___ —This work develops a new method for estimating and optimizing the directed information rate between two jointly stationary and ergodic stochastic processes. Building upon recent advances in machine learning, we propose a recurrent neural network (RNN)-based estimator which is optimized via gradient ascent over the RNN parameters. The estimator does not require prior knowledge of the underlying joint/marginal distributions and can be easily optimized over continuous input processes realized by a deep generative model. We prove consistency of the proposed estimation and optimization methods and combine them to obtain end-to-end performance guarantees. Applications for channel capacity estimation of continuous channels with memory are explored, and empirical results demonstrating the scalability and accuracy of our method are provided. When the channel is memoryless, we investigate the mapping learned by the optimized input generator.\n",
    "\n",
    "##### Index Terms—Channel capacity, directed information, neural estimation, recurrent neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f0bfb-bd47-43ae-9301-a1ae721a0584",
   "metadata": {},
   "source": [
    "### Explanation of the Paper\n",
    "\n",
    "The paper proposes a novel method for estimating and optimizing the directed information rate between two stochastic processes. Here's a breakdown of the key concepts and components of the research:\n",
    "\n",
    "#### Key Concepts\n",
    "\n",
    "1. **Directed Information Rate**:\n",
    "    - This measures the amount of information flow from one process to another over time.\n",
    "    - It is particularly useful in understanding dependencies in time series data, such as in communication systems where past outputs influence future inputs.\n",
    "\n",
    "2. **Jointly Stationary and Ergodic Stochastic Processes**:\n",
    "    - **Stationary**: The statistical properties of the process do not change over time.\n",
    "    - **Ergodic**: Time averages converge to ensemble averages, meaning long-term observations can represent the entire process.\n",
    "\n",
    "3. **Continuous Spaces**:\n",
    "    - The processes take values in continuous rather than discrete spaces, making the estimation problem more complex.\n",
    "\n",
    "#### Proposed Method\n",
    "\n",
    "1. **Recurrent Neural Network (RNN)-Based Estimator**:\n",
    "    - RNNs are a type of neural network designed to handle sequential data, making them suitable for time series analysis.\n",
    "    - The RNN is used to estimate the directed information rate without requiring prior knowledge of the underlying distributions of the processes.\n",
    "\n",
    "2. **Gradient Ascent Optimization**:\n",
    "    - The parameters of the RNN are optimized using gradient ascent, a method that iteratively adjusts parameters to maximize the directed information rate.\n",
    "\n",
    "3. **Deep Generative Model**:\n",
    "    - A model that generates continuous input processes, allowing the method to handle complex and varied data distributions.\n",
    "    - It supports the optimization process by providing realizations of the input processes.\n",
    "\n",
    "#### Consistency and Performance Guarantees\n",
    "\n",
    "- **Consistency**: The proposed estimation and optimization methods are mathematically proven to be reliable over time, meaning they converge to the true directed information rate as more data is processed.\n",
    "- **End-to-End Performance Guarantees**: By combining the estimator and optimizer, the method provides robust performance across different applications.\n",
    "\n",
    "#### Applications\n",
    "\n",
    "1. **Channel Capacity Estimation**:\n",
    "    - The method is applied to estimate the capacity of communication channels with memory (i.e., channels where past inputs affect future outputs).\n",
    "    - This is crucial for designing efficient communication systems.\n",
    "\n",
    "2. **Memoryless Channels**:\n",
    "    - Even for simpler memoryless channels (where past inputs do not affect future outputs), the method explores the input-output mappings learned by the generative model.\n",
    "    - This helps understand how the model adapts to different channel characteristics.\n",
    "\n",
    "#### Empirical Results\n",
    "\n",
    "- The paper presents empirical evidence showing that the proposed method is scalable and accurate.\n",
    "- This involves testing the method on various datasets and comparing its performance to traditional estimation methods.\n",
    "\n",
    "### Summary\n",
    "\n",
    "In essence, this research leverages advanced neural network techniques to estimate and optimize the flow of information between time-dependent processes in continuous spaces. It combines theoretical rigor with practical applications in communication system design, demonstrating both consistency and scalability in its approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d24884-17e8-4f10-9baf-156a2a700c6c",
   "metadata": {},
   "source": [
    "### Concluding Remarks and Future Work\n",
    "\n",
    "#### Summary in Layman's Terms\n",
    "\n",
    "This study introduced a new approach using neural networks to estimate and optimize the directed information (DI) rate between two time-dependent processes. Here's a breakdown of the key points and future directions:\n",
    "\n",
    "1. **Neural Estimation-Optimization Framework**:\n",
    "    - **What was done**: We developed a method that uses neural networks, specifically a modified LSTM architecture, to estimate and optimize the DI rate.\n",
    "    - **Consistency Proof**: We proved that our method consistently provides accurate results over time.\n",
    "    - **Implementation**: The implementation of this method involves using deep generative models to simulate input processes.\n",
    "\n",
    "2. **Applications and Benefits**:\n",
    "    - **Channel Capacity Estimation**: This method helps in estimating the capacity of communication channels, even when the channel's behavior is unknown or the problem is complex.\n",
    "    - **Feedback and Feedforward Scenarios**: The approach works for systems where outputs depend on past inputs (feedback) and where they do not (feedforward).\n",
    "\n",
    "3. **Empirical Validation**:\n",
    "    - **Accuracy**: Tests showed that our method's estimates closely matched theoretical solutions or known bounds, demonstrating its reliability.\n",
    "    - **Learning Input Distributions**: The model learned to generate inputs that closely approximate those which achieve the maximum capacity.\n",
    "\n",
    "4. **Strengths and Limitations**:\n",
    "    - **Strength**: Our method estimates channel capacity without needing detailed model assumptions.\n",
    "    - **Limitation**: The estimates do not necessarily provide strict lower or upper bounds on the true capacity.\n",
    "\n",
    "#### Future Work\n",
    "\n",
    "1. **Improving Theoretical Bounds**:\n",
    "    - We aim to enhance our method to provide theoretical bounds (definitive minimum or maximum values) for the estimated channel capacity.\n",
    "\n",
    "2. **Explicit Coding Schemes**:\n",
    "    - We plan to use the learned input distributions to develop explicit coding schemes that achieve optimal data transmission rates.\n",
    "\n",
    "3. **Extension to Multiuser Channels**:\n",
    "    - Expanding our method to work with channels involving multiple users, with various types of input and output data, to create a comprehensive and scalable framework.\n",
    "\n",
    "4. **Applications in Other Domains**:\n",
    "    - Applying our approach to other fields such as control systems, computer vision, speech recognition, and reinforcement learning, where understanding information flow is crucial.\n",
    "\n",
    "### Summary\n",
    "\n",
    "This work showcases a new neural network-based approach to estimate and optimize the flow of information in time-dependent processes, specifically focusing on communication channels. It proves effective and reliable through empirical studies and paves the way for future enhancements and broader applications across different domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2744a288-ad3e-46af-a366-d4034a29b8c4",
   "metadata": {},
   "source": [
    "### Optimization of the Directed Information (DI) Rate Between Two Time-Dependent Processes\n",
    "\n",
    "**Directed Information (DI) Rate**: \n",
    "Directed Information (DI) is a measure of the amount of information that flows in a particular direction between two time-dependent (sequential) processes. Unlike mutual information, which is symmetric and does not consider the directionality, DI accounts for the causal influence of past values of one process on the current and future values of another.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Time-Dependent Processes**:\n",
    "    - These are sequences of data points indexed by time, where each data point can depend on previous points in the sequence.\n",
    "    - Examples include time series data in finance, sensor data in IoT, and sequences of symbols in communication systems.\n",
    "\n",
    "2. **Directed Information Rate**:\n",
    "    - DI rate quantifies the information transfer from one process to another over time.\n",
    "    - Formally, for two processes $ X^n = (X_1, X_2, \\ldots, X_n) $ and $ Y^n = (Y_1, Y_2, \\ldots, Y_n) $, the directed information from $ X $ to $ Y $ is given by:\n",
    "      $\n",
    "      I(X^n \\rightarrow Y^n) = \\sum_{i=1}^n I(X^i; Y_i | Y^{i-1})\n",
    "      $\n",
    "      where $ X^i = (X_1, X_2, \\ldots, X_i) $ and $ Y^{i-1} = (Y_1, Y_2, \\ldots, Y_{i-1}) $.\n",
    "\n",
    "### Optimization of DI Rate\n",
    "\n",
    "**Goal**: \n",
    "The goal of optimizing the DI rate is to maximize the flow of useful information from the input process $ X $ to the output process $ Y $, under given constraints. This is crucial in applications such as communication systems, where maximizing the information transfer efficiency can significantly enhance performance.\n",
    "\n",
    "### Steps Involved in Optimization\n",
    "\n",
    "1. **Model the Processes**:\n",
    "    - Represent the time-dependent processes using appropriate statistical or machine learning models.\n",
    "    - In neural estimation frameworks, recurrent neural networks (RNNs) or Long Short-Term Memory (LSTM) networks are often used to capture the dependencies in the data.\n",
    "\n",
    "2. **Define the DI Rate**:\n",
    "    - Formulate the DI rate for the given processes. This involves calculating the conditional mutual information for each time step and summing it over the entire sequence.\n",
    "\n",
    "3. **Optimization Objective**:\n",
    "    - The optimization objective is to maximize the DI rate. This can be expressed as:\n",
    "      $\n",
    "      \\max_{\\theta} I(X^n_{\\theta} \\rightarrow Y^n)\n",
    "      $\n",
    "      where $ \\theta $ represents the parameters of the model generating the input process $ X $.\n",
    "\n",
    "4. **Parameter Estimation**:\n",
    "    - Use gradient-based optimization techniques to adjust the parameters $ \\theta $ of the model to maximize the DI rate.\n",
    "    - This typically involves backpropagation through time (BPTT) for RNNs or LSTMs, where gradients are computed and used to update the model parameters iteratively.\n",
    "\n",
    "5. **Auxiliary Models**:\n",
    "    - Deep generative models, such as variational autoencoders (VAEs) or generative adversarial networks (GANs), can be employed to model complex input processes and generate samples for optimization.\n",
    "\n",
    "### Practical Applications\n",
    "\n",
    "1. **Communication Systems**:\n",
    "    - **Channel Capacity Estimation**: Maximizing the DI rate helps in estimating the capacity of communication channels, particularly those with memory, where past inputs influence future outputs.\n",
    "    - **Optimal Input Distributions**: Learning input distributions that maximize the DI rate can guide the design of efficient coding and modulation schemes.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The optimization of the directed information rate is a powerful approach to enhancing the efficiency and performance of systems where information transfer over time is critical. By leveraging advanced neural network models and optimization techniques, this framework provides robust solutions for a wide range of applications, from communication systems to control and machine learning domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfe7707-2381-4410-b7b2-481019331dea",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [ ] [Implementation of the DINE estimator and NDT optimizer.](https://github.com/DorTsur/dine_ndt)\n",
    "- [ ] [Neural Networks MNIST](ANN-Flux-MNIST.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c02373-4525-439b-8d7f-d5172fa57e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
