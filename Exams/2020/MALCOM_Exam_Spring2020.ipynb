{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e28c9ad-ecd1-421d-8ee2-5e4f4369d287",
   "metadata": {},
   "source": [
    "## MALCOM Spring 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27da5e4-2e43-46d2-879f-46551bdee1e6",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **Multiple Choice Questions (20 points)** \n",
    "\n",
    "For each of the following questions, circle the letter of your choice. There is only ONE\n",
    "correct choice unless explicitly mentioned. No explanation is required. There is no penalty\n",
    "for a wrong answer.\n",
    "\n",
    "Alternatively, you can enter and send your answers in the separated word file provided\n",
    "together with the exam sheet.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3a0346-2adc-477d-a281-db4d5beb4971",
   "metadata": {},
   "source": [
    "**Question  &#x31;:** Which of the following models can be used in unsupervised learning? (Check all that apply)\n",
    "- (i) SVM\n",
    "- $\\boxed { \\text{(ii)  Autoencoder }}$\n",
    "- (iii) Linear regression\n",
    "- $\\boxed { \\text{(iv) k-means }}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a640ea-3efb-4c8f-a165-ef936bda03e0",
   "metadata": {},
   "source": [
    "**Question  &#x32;:** A 2-layer neural network with 5 neurons in each layer has a total of 70\n",
    "parameters (i.e. weights and biases)\n",
    "\n",
    "<img src=images/question_2-layers.png width='35%' height='35%' > </img>\n",
    "\n",
    "- (i) True\n",
    "- $\\boxed { \\text{(ii) False }}$\n",
    "\n",
    "A 2-layer neural network with 5 neurons in each layer has a total of 60 parameters, not 70. This includes 50 weights (25 {5x5} from input to hidden layer, 25 {5x5} from hidden to output layer) and 10 biases (5 for hidden layer, 5 for output layer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc6d33-fd58-44f9-93f5-9f45f088a8e1",
   "metadata": {},
   "source": [
    "**Question  &#x33;:**  Consider a trained logistic regression for a wireless communication system.\n",
    "Its weight vector is W and its test accuracy on a given data set is C. Assuming there is no\n",
    "bias, dividing W by 2 will change the test accuracy.\n",
    "\n",
    "$\\boxed { \\text{(i) True }}$\n",
    "- (ii) False\n",
    "\n",
    "Dividing the weight vector $ \\mathbf{W} $ by 2 in a trained logistic regression model will change the logits and, consequently, the output probabilities of the sigmoid function, affecting the test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522043bd-708a-4f3b-abb1-05480ab15c8f",
   "metadata": {},
   "source": [
    "**Question  &#x34;:**  Which of the following is true about the vanishing gradient problem? (Check\n",
    "all that apply)\n",
    "- (i) Tanh is usually preferred over sigmoid because it does not suffer from\n",
    "vanishing gradients.\n",
    "- $\\boxed { \\text{(ii)} }$ Leaky ReLU is less likely to suffer from vanishing gradients than sigmoid.\n",
    "- $\\boxed { \\text{(iii)} }$ Vanishing gradient causes deeper layers to learn more slowly than earlier\n",
    "layers.\n",
    "- $\\boxed { \\text{(iv)} }$ Weight initialization (e.g. Xavier, He) can help prevent the vanishing gradient\n",
    "problem.\n",
    "- (v) None of the above.\n",
    "\n",
    "The vanishing gradient problem is a significant issue in training deep neural networks where gradients of the loss function with respect to weights diminish exponentially as the network depth increases. This causes the weights in the earlier layers to update very slowly, resulting in slow or stalled learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6daa1a7-fd84-4770-987d-83f9899d0705",
   "metadata": {},
   "source": [
    "**Question  &#x35;:**  Which of the following propositions are ***true*** about a convolutional (CONV)\n",
    "layer? (Check all that apply.)\n",
    "\n",
    "- **$\\boxed { \\mathbf{(i)} }$ The number of weights depends on the depth of the input volume.**\n",
    "  - **True**: The number of weights in a convolutional layer is determined by the size of the filters (kernel size), the number of filters, and the depth of the input volume. For each filter, the number of weights is equal to the product of the filter dimensions and the depth of the input volume.\n",
    "\n",
    "- **$\\boxed { \\mathbf{(ii)} }$ The number of biases is equal to the number of filters.**\n",
    "  - **True**: Each filter has one bias term associated with it. Therefore, the number of biases is equal to the number of filters.\n",
    "\n",
    "- **(iii) The total number of parameters depends on the stride.**\n",
    "  - **False**: The total number of parameters (weights and biases) in a convolutional layer is independent of the stride. Stride affects the output dimensions of the feature map, not the number of parameters.\n",
    "\n",
    "- **(iv) The total number of parameters depends on the padding.**\n",
    "  - **False**: Similar to stride, padding affects the dimensions of the output feature map but not the number of parameters. The parameters (weights and biases) are determined by the filter size, number of filters, and input depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69171e1a-d241-48ea-b002-617732287f6b",
   "metadata": {},
   "source": [
    "**Question  &#x36;:**  Consider a Generative Adversarial Network (GAN) that successfully\n",
    "produces images of lions. Which of the following propositions is ***false***?\n",
    "\n",
    "- **(i) The generator aims to learn the distribution of lion images.**\n",
    "  - **True**: The generator's goal is to learn the underlying distribution of the training data (in this case, lion images) so that it can generate new samples that resemble the original data.\n",
    "\n",
    "- **$\\boxed { \\mathbf{(ii)} }$ The discriminator can be used to classify images as lion vs. non-lion.**\n",
    "  - **False**: The discriminator in a GAN is trained to distinguish between real images (from the training set) and fake images (generated by the generator). It is not specifically trained to classify images as lion vs. non-lion unless the non-lion images were part of the training set for the discriminator.\n",
    "\n",
    "- **(iii) After training the GAN, the discriminator loss eventually reaches a constant value.**\n",
    "  - **True**: After extensive training, the GAN can reach a state where the generator produces images so well that the discriminator cannot easily distinguish between real and fake images. In this scenario, the discriminator's loss may stabilize at a value indicating its inability to improve further.\n",
    "\n",
    "- **(iv) The generator can produce unseen images of lions.**\n",
    "  - **True**: The generator, having learned the distribution of lion images, can generate new and previously unseen images of lions that are not present in the training dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e90483-118e-4463-99f3-dd96e0dfe614",
   "metadata": {},
   "source": [
    "**Question  &#x37;:** Which of the following is true, given the optimal learning rate?\n",
    "- **(i) Batch gradient descent is always guaranteed to converge to the global optimum of a loss function.**\n",
    "  - **False**: While batch gradient descent can converge to the global optimum for convex loss functions, it is not guaranteed to converge to the global optimum for non-convex loss functions.\n",
    "\n",
    "- **(ii) Stochastic gradient descent is always guaranteed to converge to the global optimum of a loss function.**\n",
    "  - **False**: Stochastic gradient descent (SGD) is not always guaranteed to converge to the global optimum due to its inherent randomness, especially for non-convex loss functions. It may only converge to a local optimum or saddle point.\n",
    "\n",
    "- **(iii) For convex loss functions, stochastic gradient descent is guaranteed to eventually converge to the global optimum while batch gradient descent is not.**\n",
    "  - **False**: Both batch gradient descent and stochastic gradient descent are capable of converging to the global optimum for convex loss functions, given appropriate conditions such as an optimal learning rate.\n",
    "\n",
    "- **$\\boxed { \\mathbf{(iv)} }$ For convex loss functions, both stochastic gradient descent and batch gradient descent will eventually converge to the global optimum.**\n",
    "  - **True**: For convex loss functions, both batch gradient descent and stochastic gradient descent will eventually converge to the global optimum, given an optimal learning rate and sufficient iterations.\n",
    "\n",
    "- **(v) For convex loss functions, neither stochastic gradient descent nor batch gradient descent are guaranteed to converge to the global optimum.**\n",
    "  - **False**: For convex loss functions, both methods are guaranteed to converge to the global optimum under proper conditions.\n",
    "\n",
    "- **(vi) For convex loss functions, batch gradient descent is guaranteed to eventually converge to the global optimum while stochastic gradient descent is not.**\n",
    "  - **False**: Both methods will converge to the global optimum for convex loss functions, given an optimal learning rate and enough iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5236075-9ff9-43fe-8d05-184eb953e4fc",
   "metadata": {},
   "source": [
    "**Question  &#x38;:** in which distributed system architecture, I can have model consistency at\n",
    "each training epoch/iteration. (Choose all that apply)\n",
    "- **$\\boxed { \\mathbf{(i)} }$ Parameter server (PS) with synchronous SGD**\n",
    "  - **True**: In a parameter server with synchronous SGD, all workers synchronize their updates with the parameter server at each iteration. This ensures that the model parameters are consistent across all workers after each iteration.\n",
    "\n",
    "- **(ii) PS with asynchronous SGD**\n",
    "  - **False**: In a parameter server with asynchronous SGD, workers update the parameter server independently and do not wait for other workers. This can lead to stale gradients and inconsistencies in the model parameters at each iteration.\n",
    "\n",
    "- **$\\boxed { \\mathbf{(iii)} }$ All reduce**\n",
    "  - **True**: In the all-reduce architecture, each worker computes gradients and then uses an all-reduce operation to average these gradients across all workers. This ensures that all workers have consistent model parameters after each iteration.\n",
    "\n",
    "- **(iv) Gossip/decentralized**\n",
    "  - **False**: In gossip or decentralized architectures, workers communicate with a subset of other workers and gradually propagate updates throughout the network. This can lead to eventual consistency, but not necessarily consistency at each iteration.\n",
    "\n",
    "- **(v) None of the above**\n",
    "  - **False**: Options (i) and (iii) provide model consistency at each training epoch/iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee89783-2885-4f85-8d35-43364412c29a",
   "metadata": {},
   "source": [
    "**Question  &#x39;:**  In 1-bit gradient quantization, ‚Ä¶.\n",
    "\n",
    "- **(i) the quantization function is unbiased**\n",
    "  - **False**: 1-bit quantization is generally biased because it reduces the gradient values to only two possible states (+1 or -1), which can introduce significant quantization error. This can cause a systematic deviation from the true gradient values, making the quantization function biased.\n",
    "\n",
    "- **(ii) a gradient descent method will always converge**\n",
    "  - **False**: Convergence is not guaranteed when using 1-bit gradient quantization due to the high level of quantization error and the potential loss of important information in the gradient values. The method may struggle to accurately follow the descent path, especially in more complex or noisy optimization landscapes.\n",
    "\n",
    "- **$\\boxed { \\mathbf{(iii)} }$ none of the above**\n",
    "  - **True**: Since both (i) and (ii) are false, the correct answer is \"none of the above.\"\n",
    "\n",
    "1-bit gradient quantization refers to the process of reducing the precision of gradient values to just 1 bit, typically representing them as either +1 or -1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be5b51b-fc56-437a-8051-3c939628a67d",
   "metadata": {},
   "source": [
    "**Question  &#x31;&#x30;:**  Mini-batch gradient descent is a better optimizer than full-batch gradient\n",
    "descent to avoid getting stuck in saddle points.\n",
    "\n",
    "- **$\\boxed { \\mathbf{(i) True }}$**\n",
    "- **(ii) False**\n",
    "\n",
    "Mini-batch gradient descent is indeed often considered a better optimizer than full-batch gradient descent for avoiding saddle points. This is because mini-batch gradient descent introduces some level of stochasticity (randomness) by using only a subset of the data at each iteration. This randomness can help the optimizer escape from saddle points, which are flat regions in the loss surface where gradients are zero in all directions.\n",
    "\n",
    "In contrast, full-batch gradient descent uses the entire dataset to compute the gradients at each step. This can result in deterministic updates that may get stuck in saddle points or local minima.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d23d82-937a-4cac-b371-9b5c1f132224",
   "metadata": {},
   "source": [
    "**Question  &#x31;&#x31;:**  The gradient estimated during a step of mini-batch gradient descent has\n",
    "on average a lower bias when the data is i.i.d. (independent and identically distributed).\n",
    "\n",
    "- **$\\boxed { \\mathbf{(i) True }}$**\n",
    "- **(ii) False**\n",
    "\n",
    "When the data is i.i.d., each mini-batch is a representative subset of the entire dataset. This means the gradients computed from mini-batches are unbiased estimators of the true gradient of the loss function over the entire dataset. The randomness introduced by selecting different mini-batches averages out, and the expected value of the mini-batch gradient is equal to the true gradient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7068eff1-d61b-4570-9b3e-71d510fceeb3",
   "metadata": {},
   "source": [
    "**Question  &#x31;&#x32;:** You are doing full batch gradient descent using the entire training set (not stochastic gradient descent). It is necessary to shuffle the training data.\n",
    "- **(i) True**\n",
    "- **$\\boxed { \\mathbf{(ii) False }}$**\n",
    "\n",
    "When using full batch gradient descent, the entire training set is used to compute the gradient in each iteration. Since the entire dataset is used, the order of the data does not affect the computation of the gradient. Shuffling the data is crucial for methods like stochastic gradient descent or mini-batch gradient descent to ensure that each mini-batch is a good representative of the overall data distribution and to help the model generalize better. However, for full batch gradient descent, shuffling the data is not necessary because the entire dataset is used in every update step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5350f09d-939f-4fe3-87b0-044f2b0bcf8a",
   "metadata": {},
   "source": [
    "**Question  &#x31;&#x33;:** You are designing a model to predict the presence (labeled 1) or absence\n",
    "(labeled 0) of a pedestrian, to prevent accidents in an autonomous car. Which of the\n",
    "following evaluation metrics would you choose to use?\n",
    "\n",
    "- **(i) Loss function value**\n",
    "  - This provides information about how well the model is fitting the training data but does not directly translate to model performance in terms of safety-critical measures.\n",
    "\n",
    "- **$\\boxed{\\mathbf{(ii)} Metric }$ $ A = \\frac{\\text{True positive examples}}{\\text{Total positive examples}} $**\n",
    "  - This is the recall (or sensitivity) metric. Recall measures the proportion of actual positives (pedestrians) that are correctly identified by the model. High recall is crucial in this context because missing a pedestrian (false negative) could result in an accident.\n",
    "\n",
    "- **(iii) Metric $ B = \\frac{\\text{True positive examples}}{\\text{Total predicted positive examples}} $**\n",
    "  - This is the precision metric. Precision measures the proportion of predicted positives (detections of pedestrians) that are actually correct. While important, precision is less critical in this safety context than recall. Prioritizing recall ensures that pedestrians are detected whenever they are present, even if it means a higher number of false positives.\n",
    "\n",
    "- **(iv) Accuracy**\n",
    "  - Accuracy measures the proportion of correctly predicted examples (both positives and negatives) out of the total examples. However, accuracy can be misleading in imbalanced datasets where the number of negative examples (absence of pedestrians) is much higher than the number of positive examples. High accuracy could still result from poor performance in detecting pedestrians.\n",
    "\n",
    "In the context of predicting the presence or absence of a pedestrian to prevent accidents in an autonomous car, it is crucial to prioritize safety. The evaluation metric should effectively measure the model's ability to correctly identify pedestrians (positive examples) while minimizing the risk of false negatives (failing to detect a pedestrian).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8457fd78-140c-4d98-93f8-05d9ed6c7b8c",
   "metadata": {},
   "source": [
    "**Question  &#x31;&#x34;:** You design the following 2-layer fully connected neural network. All\n",
    "activations are sigmoids and your optimizer is stochastic gradient descent. You initialize\n",
    "all the weights and biases to zero and forward propagate an input $ùë• \\in \\mathbb{R}^{ùëõ√ó1}$ in the\n",
    "network. What is the output $\\hat{ùë¶}$?\n",
    "\n",
    "<img src=images/question_14-cnn.png width='50%' height='50%' > </img>\n",
    "\n",
    "- (i) -1\n",
    "- (ii) 0\n",
    "- $\\boxed{\\text{(iii) 0.5}}$\n",
    "- (iv) 1\n",
    "\n",
    "\n",
    "1. **Initialization**:\n",
    "   - All weights $ W $ and biases $ b $ are initialized to zero.\n",
    "\n",
    "2. **Forward Propagation**:\n",
    "   - For the first layer, the activations $ a_1^{[1]}, a_2^{[1]}, a_3^{[1]}, a_4^{[1]} $ are computed as follows:\n",
    "     $\n",
    "     a_j^{[1]} = \\sigma(W^{[1]} x + b^{[1]}) \\quad \\text{for } j = 1, 2, 3, 4\n",
    "     $\n",
    "     Since all weights $ W^{[1]} $ and biases $ b^{[1]} $ are zero:\n",
    "     $\n",
    "     W^{[1]} x + b^{[1]} = 0\n",
    "     $\n",
    "     The sigmoid activation function $ \\sigma $ is given by:\n",
    "     $\n",
    "     \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "     $\n",
    "     So, for $ z = 0 $:\n",
    "     $\n",
    "     \\sigma(0) = \\frac{1}{1 + e^{0}} = \\frac{1}{2} = 0.5\n",
    "     $\n",
    "     Therefore:\n",
    "     $\n",
    "     a_j^{[1]} = 0.5 \\quad \\text{for all } j\n",
    "     $\n",
    "\n",
    "   - For the second layer, the activations $ a_1^{[2]}, a_2^{[2]}, a_3^{[2]} $ are computed similarly:\n",
    "     $\n",
    "     a_k^{[2]} = \\sigma(W^{[2]} a^{[1]} + b^{[2]}) \\quad \\text{for } k = 1, 2, 3\n",
    "     $\n",
    "     Again, since all weights $ W^{[2]} $ and biases $ b^{[2]} $ are zero:\n",
    "     $\n",
    "     W^{[2]} a^{[1]} + b^{[2]} = 0\n",
    "     $\n",
    "     Thus:\n",
    "     $\n",
    "     a_k^{[2]} = 0.5 \\quad \\text{for all } k\n",
    "     $\n",
    "\n",
    "   - For the output layer, the activation $ a_1^{[3]} $ (which is $ \\hat{y} $) is computed as:\n",
    "     $\n",
    "     \\hat{y} = \\sigma(W^{[3]} a^{[2]} + b^{[3]})\n",
    "     $\n",
    "     Since all weights $ W^{[3]} $ and biases $ b^{[3]} $ are zero:\n",
    "     $\n",
    "     W^{[3]} a^{[2]} + b^{[3]} = 0\n",
    "     $\n",
    "     Therefore:\n",
    "     $\n",
    "     \\hat{y} = \\sigma(0) = 0.5\n",
    "     $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3411e284-fa28-4f3e-adc1-9576b65d73ee",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **Short Answers Questions (40 points)** \n",
    "\n",
    "For the questions in this section, please be concise and provide 2-3 sentences in your\n",
    "responses.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cbb831-b7f9-4bb4-b2cd-97431f69eee8",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **Question &#x31;:**  \n",
    "\n",
    "Why do the layers in a deep neural network architecture need to be non-linear? In other words, why linear layer is not desirable in neural nets?\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d72197-5a1d-42bd-add5-75213d1a338b",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Because linear functions are closed under composition, this is equivalent to having a single layer. Therefore, no matter how many layers exist, the network can only learn linear functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5a1278-e10a-4b86-8a9f-a63d5a455c90",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **Question &#x32;** \n",
    "\n",
    "You are solving a binary classification task for a wifi modulation signal problem. The final two layers in your network are a ReLU activation followed by a sigmoid activation. What will happen?\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e3cec5-abf7-47c1-96c0-fd4b65d5b535",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Using ReLU then sigmoid will cause all predictions to be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94a466f-bb71-4d4c-8320-bcbe7d96be97",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **Question &#x33;** \n",
    "\n",
    "Softmax takes in an n-dimensional vector $x$  and outputs another n-dimensional vector $y$:\n",
    "\n",
    "$$\n",
    "y = \\frac{e^{x_i}}{\\sum_k e^{x_k}}\n",
    "$$\n",
    "\n",
    "The objective is to compute the gradient of $y$ w.r.t $x$. Let $\\delta_{ij} = \\frac{\\partial y_i}{\\partial y_j}$. Derive an expression for $(i) \\delta_{ii}$, $(ii) \\delta_{i,j}$ when $i \\neq j$.\n",
    "\n",
    "Hint: Quotient rule of calculus. Let $h(x) = \\frac{f(x)}{g(x)}$ then $\n",
    "\\frac{\\partial h}{\\partial x} = \\frac{\\frac{\\partial f(x)}{\\partial x} * g(x) - \\frac{\\partial g(x)}{\\partial x} * f(x)}{ (g(x))^2}\n",
    "$\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8541e7c3-cfdb-4596-899e-2f8f1a281d8a",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Let's denote $f(x)= e^{x_i}$; $g(x) = \\sum e^{x_k}$ \n",
    "\n",
    "- [ ]  When $ i = j $:\n",
    "\n",
    "$\n",
    "\\begin{flalign*}\n",
    "\\delta_{ii} &= \\frac{\\partial y_i}{\\partial x_i} = \\frac{\\frac{\\partial f(x)}{\\partial x} * g(x) - \\frac{\\partial g(x)}{\\partial x} * f(x)}{ (g(x))^2} = \\frac{e^{x_i} \\displaystyle\\sum_k e^{x_k} - e^{x_i} e^{x_i}}{(\\displaystyle\\sum_k e^{x_k})^2} \\\\\n",
    "&= \\frac{e^{x_i} \\sum_k e^{x_k}}{(\\sum_{k} e^{x_k})^2} - \\frac{e^{2x_i}}{(\\sum_{k} e^{x_k})^2} = \\frac{e^{x_i}}{\\sum_{k} e^{x_k}} \\cdot \\left( \\frac{\\sum_{k} e^{x_k}}{\\sum_{k} e^{x_k}} \\right) - \\frac{e^{x_i}}{\\sum_{k} e^{x_k}} \\cdot \\frac{e^{x_i}}{\\sum_{k} e^{x_k}} \\\\\n",
    "\\text{where} \\, y_i &= \\frac{e^{x_i}}{\\sum_{k} e^{x_k}} \\text{ substitutes into: } \\to y_i \\qquad \\cdot \\qquad 1 \\qquad - \\qquad y_i \\qquad \\cdot \\qquad y_i \\; = y_i - y_i^2 \\; = y_i (1 - y_i) \\\\\n",
    "&= \\frac{e^{x_i} ( \\displaystyle\\sum_k e^{x_k} - e^{x_i}) }{(\\displaystyle\\sum_k e^{x_k})^2} = y (1 - y)\n",
    "\\end{flalign*}\n",
    "$\n",
    "\n",
    "- [ ] When $ i \\neq j $:\n",
    "\n",
    "To derive the expression for $\\delta_{ij}$ when $i \\neq j$, we'll use the softmax function and the quotient rule.\n",
    "\n",
    "Given the softmax function: $y_i = \\frac{e^{x_i}}{\\sum_{k} e^{x_k}}$, we want to find $\\delta_{ij} = \\frac{\\partial y_i}{\\partial x_j}$ for $i \\neq j$.\n",
    "\n",
    "Using the quotient rule:$\\frac{\\partial y_i}{\\partial x_j} = \\frac{\\partial}{\\partial x_j} \\left( \\frac{e^{x_i}}{\\sum_{k} e^{x_k}} \\right)$, Let's set: $f(x) = e^{x_i}, \\quad g(x) = \\sum_{k} e^{x_k}$. Then, by the quotient rule: $\n",
    "\\frac{\\partial y_i}{\\partial x_j} = \\frac{\\frac{\\partial e^{x_i}}{\\partial x_j} \\cdot \\sum_{k} e^{x_k} - \\frac{\\partial \\sum_{k} e^{x_k}}{\\partial x_j} \\cdot e^{x_i}}{\\left( \\sum_{k} e^{x_k} \\right)^2}\n",
    "$\n",
    "\n",
    "First, compute the partial derivatives: $\n",
    "\\frac{\\partial e^{x_i}}{\\partial x_j} = 0 \\quad \\text{for } i \\neq j\n",
    "$\n",
    "$\n",
    "\\frac{\\partial \\sum_{k} e^{x_k}}{\\partial x_j} = e^{x_j}\n",
    "$. Recall that: $\n",
    "y_i = \\frac{e^{x_i}}{\\sum_{k} e^{x_k}} \\quad \\text{and} \\quad y_j = \\frac{e^{x_j}}{\\sum_{k} e^{x_k}}\n",
    "$\n",
    "\n",
    "Substitute these into the quotient rule:\n",
    "$\n",
    "\\begin{flalign*}\n",
    "\\frac{\\partial y_i}{\\partial x_j} &= \\frac{0 \\cdot \\sum_{k} e^{x_k} - e^{x_j} \\cdot e^{x_i}}{\\left( \\sum_{k} e^{x_k} \\right)^2}  = \\frac{- e^{x_j} \\cdot e^{x_i}}{\\left( \\sum_{k} e^{x_k} \\right)^2}  = - \\left( \\frac{e^{x_i}}{\\sum_{k} e^{x_k}} \\right) \\left( \\frac{e^{x_j}}{\\sum_{k} e^{x_k}} \\right) = - y_i y_j\n",
    "\\end{flalign*}\n",
    "$\n",
    "\n",
    "### Final expressions:\n",
    "$\n",
    "(i) \\ \\delta_{ii} = \\frac{\\partial y_i}{\\partial x_i} = y_i (1 - y_i)\n",
    "$\n",
    "\n",
    "$\n",
    "(ii) \\ \\delta_{ij} = \\frac{\\partial y_i}{\\partial x_j} = - y_i y_j \\quad \\text{for } i \\neq j\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec6eeb6-0332-4279-8bbc-28030051d424",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **Question &#x34;** \n",
    "\n",
    "Let $s_ùëò$ be the score for a specific class $k$ and $\\theta$ is a constant that we substract\n",
    "from all scores of a sample. Show that $ùë†ùëúùëìùë°ùëöùëéùë•(ùë†_ùëò)$ is equal to $ùë†ùëúùëìùë°ùëöùëéùë•(ùë†_ùëò ‚àí \\theta)$.\n",
    "\n",
    "Explain what this property of the softmax function implies and comment on why this\n",
    "property is useful when training neural networks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467c11cc-28f2-4875-be49-ba09e89b0143",
   "metadata": {},
   "source": [
    "### Showing $ \\text{softmax}(s_k) = \\text{softmax}(s_k - \\theta) $\n",
    "\n",
    "The softmax function for score $ s_k $ is:\n",
    "$\n",
    "\\text{softmax}(s_k) = \\frac{e^{s_k}}{\\sum_j e^{s_j}}\n",
    "$\n",
    "\n",
    "For adjusted scores $ s'_k = s_k - \\theta $:\n",
    "$\n",
    "\\text{softmax}(s'_k) = \\frac{e^{s_k - \\theta}}{\\sum_j e^{s_j - \\theta}}\n",
    "$\n",
    "\n",
    "Simplify the denominator:\n",
    "$\n",
    "\\sum_j e^{s_j - \\theta} = e^{-\\theta} \\sum_j e^{s_j}\n",
    "$\n",
    "\n",
    "Substitute back:\n",
    "$\n",
    "\\text{softmax}(s'_k) = \\frac{e^{s_k - \\theta}}{e^{-\\theta} \\sum_j e^{s_j}} = \\frac{e^{s_k} e^{-\\theta}}{e^{-\\theta} \\sum_j e^{s_j}} = \\frac{e^{s_k}}{\\sum_j e^{s_j}} = \\text{softmax}(s_k)\n",
    "$\n",
    "\n",
    "### Implication\n",
    "\n",
    "This property implies that the softmax function is invariant to uniform shifts in the input scores.\n",
    "\n",
    "### Usefulness in Training Neural Networks\n",
    "\n",
    "1. **Numerical Stability:** Subtracting the maximum score from all scores prevents numerical overflow by keeping exponentiation values manageable.\n",
    "2. **Simplified Calculations:** Normalizing scores before applying softmax ensures computations remain stable and centered around zero.\n",
    "3. **Consistent Results:** Ensures consistent and stable training of neural networks by maintaining stable softmax outputs regardless of uniform shifts in scores.\n",
    "\n",
    "This property is crucial for ensuring numerical stability and consistency during neural network training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b44c9d3-3c33-41f8-9f50-045c47e7b717",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **Question &#x35;** \n",
    "\n",
    "You design a fully connected neural network architecture for an end-to-end\n",
    "communication system, where all activation functions are sigmoids. You initialize the\n",
    "weights with large positive numbers. Is this a good idea? Explain your answer.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227976f8-2cc9-4799-86e5-e2505509c16f",
   "metadata": {},
   "source": [
    "### Initializing Weights with Large Positive Numbers\n",
    "\n",
    "Initializing weights with large positive numbers in a fully connected neural network with sigmoid activations is a **bad idea** for the following reasons:\n",
    "\n",
    "1. **Sigmoid Activation Saturation:**\n",
    "   - Sigmoid outputs near 1 for large positive inputs.\n",
    "   - Causes gradient $\\sigma'(x) = \\sigma(x)(1 - \\sigma(x))$ to be very small, leading to tiny weight updates.\n",
    "\n",
    "2. **Vanishing Gradient Problem:**\n",
    "   - Saturated neurons result in extremely small gradients.\n",
    "   - Training stalls, especially in deeper networks.\n",
    "\n",
    "3. **Loss of Effective Signal Propagation:**\n",
    "   - Most neurons output values close to 1.\n",
    "   - Lack of variation in activations hinders signal and gradient propagation.\n",
    "\n",
    "### Recommended Initialization\n",
    "\n",
    "Use methods that keep weights small to maintain reasonable activations and gradients:\n",
    "\n",
    "1. **Xavier (Glorot) Initialization:**\n",
    "   - Draw weights from $\\mathcal{N}(0, \\frac{2}{n_{\\text{in}} + n_{\\text{out}}})$.\n",
    "\n",
    "2. **He Initialization:**\n",
    "   - Draw weights from $\\mathcal{N}(0, \\frac{2}{n_{\\text{in}}})$.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Large positive weight initialization is detrimental due to activation saturation and vanishing gradients. Use Xavier or He initialization to ensure effective training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988cd468-3c40-4ced-8c04-3de3ae11e615",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **Question &#x36;** \n",
    "\n",
    "We would like to implement a deep wireless transmitter by training a fully-\n",
    "connected neural network with 5 hidden layers, each with 10 hidden units. The input is a\n",
    "20-dimensional vector and the output is a scalar. What is the total number of trainable\n",
    "parameters in your network?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b85d0f1-079c-40c0-b2bc-a41905508d6f",
   "metadata": {},
   "source": [
    "To calculate the total number of trainable parameters in a fully connected neural network with 5 hidden layers (each with 10 units), a 20-dimensional input, and a scalar output:\n",
    "\n",
    "1. **Input to first hidden layer**:\n",
    "   - Weights: $20 \\times 10 = 200$\n",
    "   - Biases: $10$\n",
    "   - Total: $210$\n",
    "\n",
    "2. **Each hidden layer to the next (4 layers)**:\n",
    "   - Weights per layer: $10 \\times 10 = 100$\n",
    "   - Biases per layer: $10$\n",
    "   - Total per layer: $110$\n",
    "   - For 4 layers: $4 \\times 110 = 440$\n",
    "\n",
    "3. **Last hidden layer to output layer**:\n",
    "   - Weights: $10 \\times 1 = 10$\n",
    "   - Biases: $1$\n",
    "   - Total: $11$\n",
    "\n",
    "### Total Parameters\n",
    "$\n",
    "210 + 440 + 11 = 661\n",
    "$\n",
    "\n",
    "Thus, the total number of trainable parameters is $ \\boxed{661} $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cad868e-2dde-4d9c-bac4-c55000880950",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **Question &#x37;** \n",
    "\n",
    "We would like to design an end-to-end communication system using an autoencoder. For that, we try to find a useful representation $r \\in \\mathbb{R}^r$ of the input $s \\in \\mathbb{R}^k$ at some intermediate layer through learning to reproduce the input at the output if $k = 5$, how much $n$ should be?\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b30b46-9de9-4686-804d-c6dffae920d6",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Given $ k = 5 $ (input dimension), a reasonable choice for the intermediate layer dimension $ n $ for an autoencoder would typically be less than the input dimension to achieve compression. Therefore, a compact representation for $ n $ would be:\n",
    "\n",
    "$\n",
    "n < k \\implies n < 5\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7751b11-bad3-4489-9441-8bd61a14f987",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **Question &#x38;** \n",
    "\n",
    "Consider a distributed learning system using a parameter server if we compare $T$ iterations of 1-sample SGD with $T/B$ iterations of mini-batch (B-sample) SGD, \"B-sample\" SGD has better progress that 1-sample SGD. \n",
    "\n",
    "True or False? Comment you answer.\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532c4cfe-bf2f-4e63-b206-bf0ef9e5a2ba",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "True, in general mini-batch SGD will have better progress than 1-sample SGD because it has better convergence rate.\n",
    "\n",
    "compare with: full-batch, mini-batch and stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b989f6c0-0d43-47bd-8eeb-53302441ebb7",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **Question &#x39;** \n",
    "\n",
    "Consider a distributed learning system using a parameter server. We would like to train a useful signal vs useless signal (noise) classifier using mini-batch gradient descent. We have already split our dataset into train and test sets and the classes are balanced. The server takes the training set, splits it into batches and sends each batch to the workers in a serial (one batch after the other).\n",
    "\n",
    "For example, for $k$ workers, worker 1 receives the first $1/k$ examples, worker 2 gets the second $1/k$ examples, and so on. Withinh the training set, all signal examples are ordered in such a way that all the useful signals come first and all noise signals come after.\n",
    "\n",
    "Explain what will happen in the performance of this distributed learning system.\n",
    "How can we improve its performance?\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f07b483-f301-4e77-9d9a-312536974cc4",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "The performance will be poor as the optimization is much harder with mini-batch SGD because the loss function moves by a lot when going from one signal to another.\n",
    "\n",
    "A way to improve the performance will be to shuffle our training set before the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bcd7c2-3b6d-4db2-a75d-ad18a890b4af",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **Question &#x31;&#x30;** \n",
    "\n",
    "A binary classification problem could be solved with the two approaches\n",
    "described below:\n",
    "\n",
    "___Approach 1___: Simple Logistic Regression  (one neuron)\n",
    "\n",
    "Your output will be $\\hat{y} = \\sigma ( W_1 x + b_1)$\n",
    "\n",
    "Classify as $ 0 \\text{ if } \\hat{y} \\leq 0.5$ and $1$ otherwise.\n",
    "\n",
    "___Approach 2___: Simple Softmax Regression  (two neurons)\n",
    "\n",
    "your output will be $\\hat{y} = softmax ( W_2 \\, x + b_2) = \\left[\\hat{y}_1,\\hat{y}_2 \\right]^T$\n",
    "\n",
    "classify as $ 0 \\text{ if } \\hat{y}_1^{i} \\geq \\hat{y}_2^{ii}$ and $1$, otherwise\n",
    "\n",
    "$A_2$: involves twice as many parameters as $A_1$\n",
    "\n",
    "(i) Can $A_2$ learn more complex models than $A_1$?\n",
    "\n",
    "(ii) if yes, give the parameters $(W_2, b_2)$ of a function that can be modeled by $A_2$ but not by $A_1$. If no, show that $(W_2, b_2)$ can always be written in terms of $(W_1, b_1)$\n",
    "\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02d67e6-103f-4318-95a2-d4d03b9fa092",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "### Approach 1: Simple Logistic Regression\n",
    "\n",
    "For logistic regression:\n",
    "$\n",
    "\\hat{y} = \\sigma(W_1 x + b_1)\n",
    "$\n",
    "where $\\sigma(z) = \\frac{1}{1 + e^{-z}}$.\n",
    "\n",
    "The classification rule is:\n",
    "$\n",
    "\\text{Classify as } 0 \\text{ if } \\hat{y} \\leq 0.5 \\text{ and } 1 \\text{ otherwise.}\n",
    "$\n",
    "This can be rewritten as:\n",
    "$\n",
    "\\hat{y} \\geq 0.5 \\implies \\sigma(W_1 x + b_1) \\geq 0.5 \\implies W_1 x + b_1 \\geq 0\n",
    "$\n",
    "\n",
    "### Approach 2: Simple Softmax Regression\n",
    "\n",
    "For softmax regression: $\\hat{y} = \\text{softmax}(W_2 x + b_2) = \\left[\\hat{y}_1, \\hat{y}_2\\right]^T$ where the softmax function is: $\\hat{y}_i = \\frac{e^{z_i}}{\\sum_{j} e^{z_j}}, \\quad z = W_2 x + b_2.$\n",
    "\n",
    "Using the suggested notation:\n",
    "$\n",
    "\\hat{y}_1 = \\frac{e^{W_2^{(1)} x + b_2^{(1)}}}{e^{W_2^{(1)} x + b_2^{(1)}} + e^{W_2^{(2)} x + b_2^{(2)}}}\n",
    "$\n",
    "$\n",
    "\\hat{y}_2 = \\frac{e^{W_2^{(2)} x + b_2^{(2)}}}{e^{W_2^{(1)} x + b_2^{(1)}} + e^{W_2^{(2)}} x + b_2^{(2)}}\n",
    "$\n",
    "\n",
    "The classification rule is:\n",
    "$\n",
    "\\text{Classify as } 0 \\text{ if } \\hat{y}_1 \\geq \\hat{y}_2 \\text{ and } 1 \\text{ otherwise.}\n",
    "$\n",
    "\n",
    "This can be rewritten as:\n",
    "$\n",
    "\\hat{y}_1 \\geq \\hat{y}_2 \\implies \\frac{e^{W_2^{(1)} x + b_2^{(1)}}}{e^{W_2^{(1)} x + b_2^{(1)}} + e^{W_2^{(2)} x + b_2^{(2)}}} \\geq \\frac{e^{W_2^{(2)} x + b_2^{(2)}}}{e^{W_2^{(1)} x + b_2^{(1)}} + e^{W_2^{(2)} x + b_2^{(2)}}}\n",
    "$\n",
    "$\n",
    "\\implies e^{W_2^{(1)} x + b_2^{(1)}} \\geq e^{W_2^{(2)} x + b_2^{(2)}}\n",
    "$\n",
    "$\n",
    "\\implies W_2^{(1)} x + b_2^{(1)} \\geq W_2^{(2)} x + b_2^{(2)}\n",
    "$\n",
    "$\n",
    "\\implies (W_2^{(1)} - W_2^{(2)}) x \\geq b_2^{(2)} - b_2^{(1)}\n",
    "$\n",
    "\n",
    "To match this with logistic regression, set:\n",
    "$\n",
    "W_1 = W_2^{(1)} - W_2^{(2)}\n",
    "$\n",
    "$\n",
    "b_1 = b_2^{(2)} - b_2^{(1)}\n",
    "$\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "**(i) No, Approach 2 cannot learn more complex models than Approach 1** for a binary classification problem. They are both fundamentally linear classifiers, and thus, they have the same capacity in terms of the complexity of the models they can learn.\n",
    "\n",
    "**(ii) Show that $(W_2, b_2)$ can always be written in terms of $(W_1, b_1)$**:\n",
    "\n",
    "Given that both approaches are fundamentally the same for binary classification, the parameters of the softmax regression $(W_2, b_2)$ can be expressed in terms of the logistic regression parameters $(W_1, b_1)$.\n",
    "\n",
    "For logistic regression, the decision boundary is:\n",
    "$\n",
    "W_1 x + b_1 = 0\n",
    "$\n",
    "\n",
    "For softmax regression, we need:\n",
    "$\n",
    "\\hat{y}_1 \\geq \\hat{y}_2 \\implies W_2^{(1)} x + b_2^{(1)} \\geq W_2^{(2)} x + b_2^{(2)}\n",
    "$\n",
    "\n",
    "This simplifies to:\n",
    "$\n",
    "(W_2^{(1)} - W_2^{(2)}) x \\geq b_2^{(2)} - b_2^{(1)}\n",
    "$\n",
    "\n",
    "To match this with logistic regression, set:\n",
    "$\n",
    "W_1 = W_2^{(1)} - W_2^{(2)}\n",
    "$\n",
    "$\n",
    "b_1 = b_2^{(2)} - b_2^{(1)}\n",
    "$\n",
    "\n",
    "This shows that the parameters $(W_2, b_2)$ for the softmax function can indeed be chosen to replicate logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749374f0-8c78-4f99-afb5-df0338bd549e",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **A Practical Problem (10 points)** \n",
    "\n",
    "---\n",
    "\n",
    "You are the project manager for implementing ML-based telecom products in a famous\n",
    "company and you need to decide on the budget investment. Your company is about to\n",
    "launch two products:\n",
    "- ML-based transceiver ‚ÄúMLC1.0‚Äù, which is based on radio signal binary classification.\n",
    "- ML-based transceiver ‚ÄúMLC2.0‚Äù, which is based on variational autoencoders.\n",
    "  \n",
    "The hourly cost for labeling data is 10 euros/engineer and the hourly cost for\n",
    "testing/validation is 20 euros/engineer for MLC1.0 and 30 euros/engineer for MLC2.0.\n",
    "For achieving the same performance (e.g., accuracy) in both products, we need to\n",
    "perform 30 hours of labeling and H hours of validation.\n",
    "\n",
    "Your company allows you to hire up to 2 engineers. How many hours H you need to spend\n",
    "on validation so that MLC1.0 production costs less than MLC2.0?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d54382-aa15-48de-95cb-1285429a7a7d",
   "metadata": {},
   "source": [
    "### Cost Calculation:\n",
    "\n",
    "#### MLC1.0:\n",
    "- Hourly cost for labeling data: 10 euros/engineer\n",
    "- Hourly cost for validation: 20 euros/engineer\n",
    "- Hours of labeling required: 30 hours\n",
    "- Hours of validation required: $ H $\n",
    "\n",
    "Total cost for MLC1.0:\n",
    "$\n",
    "\\text{Cost}_{\\text{MLC1.0}} = 30 \\text{ hours} \\times 10 \\text{ euros/hour} + H \\text{ hours} \\times 20 \\text{ euros/hour}\n",
    "$\n",
    "$\n",
    "\\text{Cost}_{\\text{MLC1.0}} = 300 \\text{ euros} + 20H \\text{ euros}\n",
    "$\n",
    "\n",
    "#### MLC2.0:\n",
    "- Hourly cost for labeling data: 10 euros/engineer\n",
    "- Hourly cost for validation: 30 euros/engineer\n",
    "- Hours of labeling required: 30 hours\n",
    "- Hours of validation required: $ H $\n",
    "\n",
    "Total cost for MLC2.0:\n",
    "$\n",
    "\\text{Cost}_{\\text{MLC2.0}} = 30 \\text{ hours} \\times 10 \\text{ euros/hour} + H \\text{ hours} \\times 30 \\text{ euros/hour}\n",
    "$\n",
    "$\n",
    "\\text{Cost}_{\\text{MLC2.0}} = 300 \\text{ euros} + 30H \\text{ euros}\n",
    "$\n",
    "\n",
    "### Condition for MLC1.0 to be cheaper than MLC2.0:\n",
    "\n",
    "$\n",
    "\\text{Cost}_{\\text{MLC1.0}} < \\text{Cost}_{\\text{MLC2.0}}\n",
    "$\n",
    "$\n",
    "300 + 20H < 300 + 30H\n",
    "$\n",
    "\n",
    "Subtract 300 from both sides:\n",
    "$\n",
    "20H < 30H\n",
    "$\n",
    "\n",
    "Subtract $ 20H $ from both sides:\n",
    "$\n",
    "0 < 10H\n",
    "$\n",
    "\n",
    "Divide both sides by 10:\n",
    "$\n",
    "0 < H\n",
    "$\n",
    "\n",
    "### Conclusion:\n",
    "To ensure that the production cost of MLC1.0 is less than the production cost of MLC2.0, the number of hours $ H $ spent on validation must be greater than 0. Therefore, any positive number of hours spent on validation will satisfy this condition. Since the question implicitly assumes H to be non-zero for a meaningful comparison, we can conclude that $ H $ must be greater than 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24fb9e9-faa7-4a0c-81a4-d5e5ab9734a2",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **Exercise ‚Äì Federated Learning (30 points)** \n",
    "\n",
    "---\n",
    "\n",
    "Consider a federated learning system at the wireless edge, in which the data distribution of the edge devices is imbalanced (non i.i.d.), i.e., the local data follows different distributions. This will introduce biases in the model training and cause a decrease in accuracy of federated learning applications.\n",
    "\n",
    "To improve the performance of the system, we introduce a controller (scheduler) that selects which edge device is allowed to send its updated model back to the server.\n",
    "\n",
    "We assume that there are two possible outcomes, $x = 0$ and $x = 1$, (probability space $\\mathcal{X} = \\{0,1\\}$). The data of device 1 follows a binomial distribution with $n = 1$ and $p = 0.2$, whereas the data of device $2$ follows a binomial distribution with $n = 1$ and $p = 0.4$.\n",
    "\n",
    "The scheduler will select the edge device whose Kullback-Leibler divergence from the uniform distribution to its own distribution is smaller. Which of the two edge devices will not send its model back to the server?\n",
    "\n",
    "___Reminder:___\n",
    "\n",
    "- ___The binomial distribution , $B(n,p)$ is a discrete probability distribution with pmf (probability mass function)___\n",
    "\n",
    "$$\n",
    "f(k,n,p) = \\mathbb{P}\\left[ X = k \\right]=\\binom{n}{k} p^k (1 - p)^{n-k}\n",
    "$$\n",
    "\n",
    "- ___For discrete probability distributions $P$ and $Q$ defined on the same probability space $\\mathcal{X}$, the Kullback‚ÄìLeibler divergence from Q to P is defined to be___\n",
    "\n",
    "$$\n",
    "D_{kl}(P\\parallel Q) = \\displaystyle\\sum_{x \\in \\mathcal{X}} P(x) \\log\\Big(\\frac{P(x)}{Q(x)}\\Big)\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8039d3d0-7e43-4f3c-9c2b-be2dbbfd0ab3",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Both devices follow a special case of Binomial Distribution (i.e. Bernouilli) that according to the definition of Binomial with given parameters $(k, n, p)$, we get:\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "P_1(X = 0) &= \\binom{1}{0} (0.2)^0 (1 - 0.2)^{1 - 0} = 0.8 \\\\\n",
    "P_1(X = 1) &= \\binom{1}{1} (0.2)^1 (1 - 0.2)^{1 - 1} = 0.2 \\\\\n",
    "P_2(X = 0) &= \\binom{1}{0} (0.4)^0 (1 - 0.4)^{1 - 0} = 0.6 \\\\\n",
    "P_2(X = 1) &= \\binom{1}{1} (0.4)^1 (1 - 0.4)^{1 - 1} = 0.4\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "### Given Data:\n",
    "- Device 1: $ B(1, 0.2) $\n",
    "- Device 2: $ B(1, 0.4) $\n",
    "- Uniform distribution $ Q $: $ Q(x) = 0.5 $ for $ x = 0, 1 $\n",
    "\n",
    "### KL Divergence Calculation Using $\\log_2$:\n",
    "\n",
    "#### Device 1:\n",
    "$\n",
    "P_1(X = 0) = 0.8, \\quad P_1(X = 1) = 0.2\n",
    "$\n",
    "\n",
    "$\n",
    "D_{KL}(P_1 \\parallel Q) = 0.8 \\log_2 \\left(\\frac{0.8}{0.5}\\right) + 0.2 \\log_2 \\left(\\frac{0.2}{0.5}\\right)\n",
    "$\n",
    "$\n",
    "D_{KL}(P_1 \\parallel Q) = 0.8 \\log_2 (1.6) + 0.2 \\log_2 (0.4)\n",
    "$\n",
    "$\n",
    "\\log_2 (1.6) \\approx 0.6781, \\quad \\log_2 (0.4) \\approx -1.3219\n",
    "$\n",
    "$\n",
    "D_{KL}(P_1 \\parallel Q) = 0.8 \\cdot 0.6781 + 0.2 \\cdot (-1.3219) \\approx 0.2781\n",
    "$\n",
    "\n",
    "#### Device 2:\n",
    "$\n",
    "P_2(X = 0) = 0.6, \\quad P_2(X = 1) = 0.4\n",
    "$\n",
    "$\n",
    "D_{KL}(P_2 \\parallel Q) = 0.6 \\log_2 \\left(\\frac{0.6}{0.5}\\right) + 0.4 \\log_2 \\left(\\frac{0.4}{0.5}\\right)\n",
    "$\n",
    "$\n",
    "D_{KL}(P_2 \\parallel Q) = 0.6 \\log_2 (1.2) + 0.4 \\log_2 (0.8)\n",
    "$\n",
    "$\n",
    "\\log_2 (1.2) \\approx 0.263, \\quad \\log_2 (0.8) \\approx -0.3219\n",
    "$\n",
    "$\n",
    "D_{KL}(P_2 \\parallel Q) = 0.6 \\cdot 0.263 + 0.4 \\cdot (-0.3219) \\approx 0.02904\n",
    "$\n",
    "\n",
    "### Conclusion:\n",
    "Since $ D_{KL}(P_2 \\parallel Q) < D_{KL}(P_1 \\parallel Q) $, device 1 will not send its model back to the server.\n",
    "\n",
    "**Answer:** Device 1 will not send its model back to the server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3fa7c6-fa0d-4683-8a93-e13c29609f38",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46791cb-cf7c-432e-ac36-ad4ab21e3b83",
   "metadata": {},
   "source": [
    "#### Proof that $D_{KL}$ uses $log_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23a232d2-2673-4fd1-88be-ab837c5003aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27807190511263774"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D‚Çñ‚Çó = 0.8 * log2(0.8/0.5) + 0.2 * log2(0.2/0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce73a45-669d-4e6e-8585-6367a208543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying the values\n",
    "# Function to compute the binomial coefficient\n",
    "function binomial_coefficient(n, k)\n",
    "    return factorial(n) // (factorial(k) * factorial(n - k))\n",
    "end\n",
    "\n",
    "# Function to compute the binomial probability mass function\n",
    "function f(k, n, p)\n",
    "    return binomial_coefficient(n, k) * (p^k) * ((1 - p)^(n - k))\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "894871bd-a4cc-44af-b1e1-606261da4da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P‚ÇÅ(X = 0) = 0.8\n",
      "P‚ÇÅ(X = 1) = 0.2\n",
      "P‚ÇÇ(X = 0) = 0.6\n",
      "P‚ÇÇ(X = 1) = 0.4"
     ]
    }
   ],
   "source": [
    "# Example values\n",
    "n = 1\n",
    "k = 0\n",
    "p‚ÇÅ = 0.2 \n",
    "\n",
    "# Calculate the probability\n",
    "probability = f(k, n, p‚ÇÅ)\n",
    "println(\"P‚ÇÅ(X = $k) = $probability\")\n",
    "\n",
    "# Calculate for another value\n",
    "k = 1\n",
    "probability = f(k, n, p‚ÇÅ)\n",
    "println(\"P‚ÇÅ(X = $k) = $probability\")\n",
    "\n",
    "k = 0\n",
    "p‚ÇÇ = 0.4\n",
    "\n",
    "# Calculate the probability\n",
    "probability = f(k, n, p‚ÇÇ)\n",
    "println(\"P‚ÇÇ(X = $k) = $probability\")\n",
    "\n",
    "# Calculate for another value\n",
    "k = 1\n",
    "probability = f(k, n, p‚ÇÇ)\n",
    "print(\"P‚ÇÇ(X = $k) = $probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67ddf10b-367a-4617-8d51-d4afaaf4efe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P‚ÇÉ(X = 4) = 0.05953499999999999\n"
     ]
    }
   ],
   "source": [
    "# https://en.wikipedia.org/wiki/Binomial_distribution\n",
    "# Example\n",
    "# Suppose a biased coin comes up heads with probability 0.3 when tossed. \n",
    "# The probability of seeing exactly 4 heads in 6 tosses is:\n",
    "n = 6 # Tosses\n",
    "k = 4 # Heads\n",
    "p‚ÇÉ = 0.3\n",
    "\n",
    "# Calculate the probability\n",
    "probability = f(k, n, p‚ÇÉ)\n",
    "println(\"P‚ÇÉ(X = $k) = $probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696ed0fe-391e-4351-91da-4e147b4c2649",
   "metadata": {},
   "source": [
    "- [ ] Gradient Descent vs Gradient Ascent\n",
    "\n",
    "Both algorithms have the same concept but the `sign` changes. GD looks for `Minimizing` while GA looks for `Maximizing`\n",
    "\n",
    "Based on 22 and 23 exams\n",
    "\n",
    "- [ ] MCQ\n",
    "- [ ] only 2 parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b77af1-3d08-4763-bc04-66b829b752ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
