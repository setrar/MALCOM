{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e28c9ad-ecd1-421d-8ee2-5e4f4369d287",
   "metadata": {},
   "source": [
    "## MALCOM Spring 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cbb831-b7f9-4bb4-b2cd-97431f69eee8",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x31;)** \n",
    "\n",
    "Why do the layers in a deep neural network architecture need to be non-linear? In other words, why linear layer is not desirable in neural nets?\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d72197-5a1d-42bd-add5-75213d1a338b",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Because linear functions are closed under composition, this is equivalent to having a single layer. Therefore, no matter how many layers exist, the network can only learn linear functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5a1278-e10a-4b86-8a9f-a63d5a455c90",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x32;)** \n",
    "\n",
    "You are solving a binary classification task for a wifi modulation signal problem. The final two layers in your network are a ReLU activation followed by a sigmoid activation. What will happen?\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e3cec5-abf7-47c1-96c0-fd4b65d5b535",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Using ReLU then sigmoid will cause all predictions to be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94a466f-bb71-4d4c-8320-bcbe7d96be97",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x33;)** \n",
    "\n",
    "Softmax takes in an n-dimensional vector $x$  and outputs another n-dimensional vector $y$:\n",
    "\n",
    "$\n",
    "y = \\frac{e^{x_i}}{\\sum_k e^{x_k}}\n",
    "$\n",
    "\n",
    "The objective is to compute the gradient of $y$ w.r.t $x$. Let $\\delta_{ij} = \\frac{\\partial y_i}{\\partial y_j}$ \n",
    "\n",
    "Derive an expression for $(i) \\delta_{ii}$, $(ii) \\delta_{i,j}$ when $i \\neq j$\n",
    "\n",
    "Hint: Quotient rule of calculus. Let $h(x) = \\frac{f(x)}{g(x)}$ then $\n",
    "\\frac{\\partial h}{\\partial x} = \\frac{\\frac{\\partial f(x)}{\\partial x} * g(x) - \\frac{\\partial g(x)}{\\partial x} * f(x)}{ (g(x))^2}\n",
    "$\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8541e7c3-cfdb-4596-899e-2f8f1a281d8a",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Let's denote $f(x)= e^{x_i}$; $g(x) = \\sum e^{x_k}$ \n",
    "\n",
    "- [ ]  When $ i = j $:\n",
    "\n",
    "$$\n",
    "\\begin{flalign*}\n",
    "\\delta_{ii} &= \\frac{\\partial y_i}{\\partial x_i} = \\frac{\\frac{\\partial f(x)}{\\partial x} g(x) - \\frac{\\partial g(x)}{\\partial x} * f(x)}{ (g(x))^2} \\\\\n",
    "&= \\frac{e^{x_i} \\displaystyle\\sum_k e^{x_k} - e^{x_i} e^{x_i}}{(\\displaystyle\\sum_k e^{x_k})^2} \\\\\n",
    "&= \\frac{e^{x_i} ( \\displaystyle\\sum_k e^{x_k} - e^{x_i}) }{(\\displaystyle\\sum_k e^{x_k})^2} \\\\\n",
    "&= y (1 - y)\n",
    "\\end{flalign*}\n",
    "$$\n",
    "\n",
    "- [ ] When $ i \\neq j $:\n",
    "\n",
    "$$\n",
    "\\begin{flalign*}\n",
    "\\delta_{ij} &= \\frac{\\partial y_i}{\\partial x_j} = \\frac{0 - e^{x_i} e^{x_j}}{(\\displaystyle\\sum e^{x_k})^2} - \\frac{e^{x_i} e^{x_j}}{\\displaystyle\\sum e^{x_i} \\displaystyle\\sum e^{x_j}} \\\\\n",
    "&= -y y_j\n",
    "\\end{flalign*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a950e4a2-1972-480c-9339-a341443f784e",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x34;)** \n",
    "\n",
    "Let $s_k$ be the score for a specific class $k$ and $\\theta$ is a constant that we substract from all scores of a sample. Swho that $\\text{softmax}(s_k)$ is equal to $\\text{softmax}(s_k - \\theta)$.\n",
    "\n",
    "What does this property of the softmax function implies? Would you consider this property useful when training neural nets?\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d948bb-7795-468f-a889-4a2778aed9f2",
   "metadata": {},
   "source": [
    "Let's start by showing that $\\text{softmax}(s_k)$ is equal to $\\text{softmax}(s_k - \\theta)$.\n",
    "\n",
    "### Property Proof\n",
    "Given the softmax function for a vector of scores $ \\mathbf{s} $:\n",
    "$\n",
    "\\text{softmax}(s_k) = \\frac{e^{s_k}}{\\sum_{j=1}^{n} e^{s_j}}\n",
    "$\n",
    "\n",
    "Now, if we subtract a constant $\\theta$ from all scores, we get a new vector $ \\mathbf{s'} $ where $ s'_i = s_i - \\theta $ for all $ i $. The softmax function applied to this new vector is:\n",
    "$\n",
    "\\text{softmax}(s'_k) = \\frac{e^{s_k - \\theta}}{\\sum_{j=1}^{n} e^{s_j - \\theta}}\n",
    "$\n",
    "\n",
    "We can simplify the numerator and denominator:\n",
    "$\n",
    "\\text{softmax}(s'_k) = \\frac{e^{s_k - \\theta}}{\\sum_{j=1}^{n} e^{s_j - \\theta}} = \\frac{e^{s_k} \\cdot e^{-\\theta}}{\\sum_{j=1}^{n} e^{s_j} \\cdot e^{-\\theta}}\n",
    "$\n",
    "\n",
    "Since $ e^{-\\theta} $ is a constant and can be factored out of the sum in the denominator:\n",
    "$\n",
    "\\text{softmax}(s'_k) = \\frac{e^{s_k} \\cdot e^{-\\theta}}{e^{-\\theta} \\cdot \\sum_{j=1}^{n} e^{s_j}} = \\frac{e^{s_k}}{\\sum_{j=1}^{n} e^{s_j}}\n",
    "$\n",
    "\n",
    "Therefore,\n",
    "$\n",
    "\\boxed { \\text{softmax}(s'_k) = \\text{softmax}(s_k) }\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57941e16-9039-46e0-a022-c5a21d4cd950",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x35;)** \n",
    "\n",
    "You design a fully connected neural net architecture for an end-toend communication system, where all functions are sigmoid. You initilize the weigths with large positive numbers. Is this a good idea? Explain\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b307ff-a9a6-473b-ac72-3c5522200633",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Large weigths assumes $w_x$ to be large. When $w_x$ is large the gradient is small for sigmoid function. Hence, we encounter the vanishing gradient problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4effc529-54ae-4cf0-9b0e-fd10912b36a7",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x36;)** \n",
    "\n",
    "We would like to implement a deep wireless transmitter by training a fully connected neural net with 5 hidden layers, each with 10 hidden units. The input is a 20 dimensional vector and the output is a scalar. Calculate the total number of trainable parameters.\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc92ee01-ad9a-4369-9236-9faac1746440",
   "metadata": {},
   "source": [
    "Let's represent the calculation in a compact form. Given:\n",
    "\n",
    "- Input dimension: $ 20 $\n",
    "- Hidden layers: $ 5 $ hidden layers, each with $ 10 $ units\n",
    "- Output dimension: $ 1 $\n",
    "\n",
    "The total number of trainable parameters includes the weights and biases for each layer.\n",
    "\n",
    "### Layers Calculation\n",
    "\n",
    "1. **Input Layer to Hidden Layer 1:**\n",
    "   - Weights: $ 20 \\times 10 $\n",
    "   - Biases: $ 10 $\n",
    "\n",
    "2. **Hidden Layer $ i $ to Hidden Layer $ i+1 $ (for $ i = 1 $ to $ 4 $):**\n",
    "   - Weights: $ 10 \\times 10 $\n",
    "   - Biases: $ 10 $\n",
    "\n",
    "3. **Hidden Layer 5 to Output Layer:**\n",
    "   - Weights: $ 10 \\times 1 $\n",
    "   - Biases: $ 1 $\n",
    "\n",
    "### Total Calculation\n",
    "\n",
    "Let's sum these up:\n",
    "\n",
    "1. **Input to Hidden Layer 1:**\n",
    "   $\n",
    "   20 \\times 10 + 10 = 200 + 10 = 210\n",
    "   $\n",
    "\n",
    "2. **Hidden Layer 1 to Hidden Layer 2:**\n",
    "   $\n",
    "   10 \\times 10 + 10 = 100 + 10 = 110\n",
    "   $\n",
    "\n",
    "3. **Hidden Layer 2 to Hidden Layer 3:**\n",
    "   $\n",
    "   10 \\times 10 + 10 = 100 + 10 = 110\n",
    "   $\n",
    "\n",
    "4. **Hidden Layer 3 to Hidden Layer 4:**\n",
    "   $\n",
    "   10 \\times 10 + 10 = 100 + 10 = 110\n",
    "   $\n",
    "\n",
    "5. **Hidden Layer 4 to Hidden Layer 5:**\n",
    "   $\n",
    "   10 \\times 10 + 10 = 100 + 10 = 110\n",
    "   $\n",
    "\n",
    "6. **Hidden Layer 5 to Output Layer:**\n",
    "   $\n",
    "   10 \\times 1 + 1 = 10 + 1 = 11\n",
    "   $\n",
    "\n",
    "### Sum of All Parameters\n",
    "\n",
    "$\n",
    "210 + 110 + 110 + 110 + 110 + 11 = 661\n",
    "$\n",
    "\n",
    "Thus, in a compact form, the total number of trainable parameters is $ \\boxed{661} $.\n",
    "\n",
    "$\\text{\\# weights} = (20 * 10) + ... = 610 $\n",
    "\n",
    "$\\text{\\# bins} = 51$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cad868e-2dde-4d9c-bac4-c55000880950",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x37;)** \n",
    "\n",
    "We would like to design an end-to-end communication system using an autoencoder. For that, we try to find a useful representation $r \\in \\mathbb{R}^r$ of the input $s \\in \\mathbb{R}^k$ at some intermediate layer through learning to reproduce the input at the output if $k = 5$, how much $n$ should be?\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b30b46-9de9-4686-804d-c6dffae920d6",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Given $ k = 5 $ (input dimension), a reasonable choice for the intermediate layer dimension \\( n \\) for an autoencoder would typically be less than the input dimension to achieve compression. Therefore, a compact representation for \\( n \\) would be:\n",
    "\n",
    "$\n",
    "n < k \\implies n < 5\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7751b11-bad3-4489-9441-8bd61a14f987",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x38;)** \n",
    "\n",
    "Consider a distributed learning system using a parameter server if we compare $T$ iterations of 1-sample SGD with $T/B$ iterations of mini-batch (B-sample) SGD, \"B-sample\" SGD has better progress that 1-sample SGD. \n",
    "\n",
    "True or False? Comment you answer.\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532c4cfe-bf2f-4e63-b206-bf0ef9e5a2ba",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "True, in general mini-batch SGD will have better progress than 1-sample SGD because it has better convergence rate.\n",
    "\n",
    "compare with: full-batch, mini-batch and stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b989f6c0-0d43-47bd-8eeb-53302441ebb7",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x39;)** \n",
    "\n",
    "Consider a distributed learning system using a parameter server. We would like to train a useful signal vs useless signal (noise) classifier using mini-batch gradient descent. We have already split our dataset into train and test sets and the classes are balanced. The server takes the training set, splits it into batches and sends each batch to the workers in a serial (one batch after the other).\n",
    "\n",
    "For example, for $k$ workers, worker 1 receives the first $1/k$ examples, worker 2 gets the second $1/k$ examples, and so on. Withinh the training set, all signal examples are ordered in such a way that all the useful signals come first and all noise signals come after.\n",
    "\n",
    "Explain what will happen in the performance of this distributed learning system.\n",
    "How can we improve its performance?\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f07b483-f301-4e77-9d9a-312536974cc4",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "The performance will be poor as the optimization is much harder with mini-batch SGD because the loss function moves by a lot when going from one signal to another.\n",
    "\n",
    "A way to improve the performance will be to shuffle our training set before the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bcd7c2-3b6d-4db2-a75d-ad18a890b4af",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x41;)** \n",
    "\n",
    "A binary classification problem could be solved with the two approaches\n",
    "described below:\n",
    "\n",
    "Approach 1: Simple Logistic Regression  (one neuron)\n",
    "\n",
    "Your output will be $\\hat{y} = \\sigma ( W_1 x + b_1)$\n",
    "\n",
    "Classify as $ 0 \\text{ if } \\hat{y} \\leq 0.5$ and $1$ otherwise.\n",
    "\n",
    "Approach 2: Simple Softmax Regression  (two neurons)\n",
    "\n",
    "your output will be $\\hat{y} = softmax ( W_2 \\, x + b_2) = \\left[\\hat{y}_1,\\hat{y}_2 \\right]^T$\n",
    "\n",
    "classify as $ 0 \\text{ if } \\hat{y}_1^{i} \\geq \\hat{y}_2^{ii}$ and $1$, otherwise\n",
    "\n",
    "$A_2$: involves twice as many parameters as $A_1$\n",
    "\n",
    "(i) Can $A_2$ learn more complex models than $A_1$?\n",
    "\n",
    "(ii) if yes, give the parameters $(W_2, b_2)$ of a function that can be modeled by $A_2$ but not by $A_1$. If no, show that $(W_2, b_2)$ can always be written in terms of $(W_1, b_1)$\n",
    "\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02d67e6-103f-4318-95a2-d4d03b9fa092",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "(i) No, it cannot\n",
    "\n",
    "(ii) For $A_1$, the classifier is $\\sigma ( w_1 x + b_1) \\geq 0.5$ which is equivalent to $\\sigma ( w_1 x + b_1) \\geq 0$ For $A_2$, the classifier is $\\frac{e^{w_2^{(1)} x + b_2^{(1)}}}{}$\n",
    "\n",
    "\n",
    "\n",
    "Hence from the last expression we can deduce that given any w2 and b2 in $A_2$, we can get the exact same model in $A_1$ by setting $w_1 = w_2^{(1)} - w_2^{(2)}$ and $b_1 = b_1^{(1)} - b_2^{(2)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24fb9e9-faa7-4a0c-81a4-d5e5ab9734a2",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **Exercise – Federated Learning (30 points)** \n",
    "\n",
    "---\n",
    "\n",
    "Consider a federated learning system at the wireless edge, in which the data distribution of the edge devices is imbalanced (non i.i.d.), i.e., the local data follows different distributions. This will introduce biases in the model training and cause a decrease in accuracy of federated learning applications.\n",
    "\n",
    "To improve the performance of the system, we introduce a controller (scheduler) that selects which edge device is allowed to send its updated model back to the server.\n",
    "\n",
    "We assume that there are two possible outcomes, $x = 0$ and $x = 1$, (probability space $\\mathcal{X} = \\{0,1\\}$). The data of device 1 follows a binomial distribution with $n = 1$ and $p = 0.2$, whereas the data of device $2$ follows a binomial distribution with $n = 1$ and $p = 0.4$.\n",
    "\n",
    "The scheduler will select the edge device whose Kullback-Leibler divergence from the uniform distribution to its own distribution is smaller. Which of the two edge devices will not send its model back to the server?\n",
    "\n",
    "___Reminder:___\n",
    "\n",
    "- ___The binomial distribution , $B(n,p)$ is a discrete probability distribution with pmf (probability mass function)___\n",
    "\n",
    "$$\n",
    "f(k,n,p) = \\mathbb{P}\\left[ X = k \\right]=\\binom{n}{k} p^k (1 - p)^{n-k}\n",
    "$$\n",
    "\n",
    "- ___For discrete probability distributions $P$ and $Q$ defined on the same probability space $\\mathcal{X}$, the Kullback–Leibler divergence from Q to P is defined to be___\n",
    "\n",
    "$$\n",
    "D_{kl}(P\\parallel Q) = \\displaystyle\\sum_{x \\in \\mathcal{X}} P(x) \\log\\Big(\\frac{P(x)}{Q(x)}\\Big)\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8039d3d0-7e43-4f3c-9c2b-be2dbbfd0ab3",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Both devices follow a special case of Binomial Distribution (i.e. Bernouilli) that according to the definition of Binomial with given parameters $(k, n, p)$, we get:\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "P_1(x = 0) &= \\binom{1}{0} (0.2)^0 (1 - 0.2)^{1 - 0} - 0.8 \\\\\n",
    "P_2(x = 1) &= 0.6\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "Now considering uniform distribution such that $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e3bca4-b176-4591-8e20-22d97e5d1a98",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696ed0fe-391e-4351-91da-4e147b4c2649",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [ ] Gradient Descent vs Gradient Ascent\n",
    "\n",
    "Both algorithms have the same concept but the `sign` changes. GD looks for `Minimizing` while GA looks for `Maximizing`\n",
    "\n",
    "Based on 22 and 23 exams\n",
    "\n",
    "- [ ] MCQ\n",
    "- [ ] only 2 parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b77af1-3d08-4763-bc04-66b829b752ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
