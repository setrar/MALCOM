{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "527f6936-30c5-453f-bc46-379a95091e2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `@epochs` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `@epochs` not defined",
      ""
     ]
    }
   ],
   "source": [
    "using MLDatasets\n",
    "using Flux, Statistics\n",
    "using Flux.Data: DataLoader\n",
    "using Flux.Optimise: Optimiser\n",
    "using Flux: onehotbatch, onecold, @epochs\n",
    "using Flux.Losses: logitcrossentropy\n",
    "using Base: @kwdef\n",
    "using CUDA\n",
    "using MLDatasets\n",
    "using Images\n",
    "using ProgressBars\n",
    "\n",
    "\n",
    "function get_data(args)\n",
    "    ENV[\"DATADEPS_ALWAYS_ACCEPT\"] = \"true\"\n",
    "\n",
    "    # load train and test dataset\n",
    "    x_train, y_train = CIFAR10.traindata(Float32)\n",
    "    x_test,  y_test  = CIFAR10.testdata(Float32)\n",
    "\n",
    "    # reshape\n",
    "    x_train = reshape(x_train, 32, 32, 3, :)\n",
    "    x_test = reshape(x_test, 32, 32, 3, :)\n",
    "\n",
    "    # resize\n",
    "    x_train = imresize(x_train, (64, 64, 3))\n",
    "    x_test = imresize(x_test, (64, 64, 3))\n",
    "\n",
    "    # one-hot-encode the labels\n",
    "    y_train = onehotbatch(y_train, 0:9)\n",
    "    y_test = onehotbatch(y_test, 0:9)\n",
    "\n",
    "    train_loader = DataLoader((x_train, y_train), batchsize=args.batchsize, partial=false, shuffle=true)\n",
    "    test_loader = DataLoader((x_test, y_test), batchsize=args.batchsize, partial=false)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "function loss_function(ŷ, y)\n",
    "    logitcrossentropy(ŷ, y)\n",
    "end\n",
    "\n",
    "\n",
    "function evaluation_loss_accuracy(loader, model)\n",
    "\n",
    "    loss, accuracy, counter = 0f0, 0f0, 0\n",
    "\n",
    "    for (x,y) in loader\n",
    "        ŷ = model(x)\n",
    "        loss += loss_function(ŷ,y)\n",
    "        accuracy += sum(onecold(ŷ) .== onecold(y))\n",
    "        counter +=  1\n",
    "    end\n",
    "\n",
    "    return loss / counter, accuracy / counter\n",
    "end\n",
    "\n",
    "# AdaptiveMeanPool cannot be used with 64x64 because it will throw a \n",
    "# DimensionMismatch. You can use it with 256x256 or bigger images\n",
    "# For more information refer to: https://github.com/FluxML/model-zoo/issues/334\n",
    "function set_model(; imgsize=(64, 64,3), num_classes=10)\n",
    "    return Chain(\n",
    "                Conv((11, 11), imgsize[end]=>64, stride=(4,4), relu, pad=(2,2)),\n",
    "                MaxPool((3, 3), stride=(2,2)),  \n",
    "                Conv((5, 5), 64=>192, relu, pad=(2,2)),\n",
    "                MaxPool((3, 3), stride=(2,2)),\n",
    "                Conv((3, 3), 192=>384, relu, pad=(1,1)),\n",
    "                Conv((3, 3), 384=>256, relu, pad=(1,1)),\n",
    "                Conv((3, 3), 256=>256, relu, pad=(1,1)),\n",
    "                MaxPool((3, 3), stride=(2,2)),\n",
    "                # AdaptiveMeanPool((6, 6)), \n",
    "                flatten,\n",
    "                Dropout(0.5),\n",
    "                Dense(256*1*1, 4096, relu), # With AdaptiveMeanPool((6, 6)) set 256 * 6 * 6\n",
    "                Dropout(0.5),\n",
    "                Dense(4096, 4096, relu),\n",
    "                Dense(4096, num_classes))\n",
    "end\n",
    "\n",
    "\n",
    "Base.@kwdef mutable struct Args\n",
    "    η = 1e-4             # learning rate\n",
    "    batchsize = 128     # batch size\n",
    "    epochs = 1          # number of epochs\n",
    "end\n",
    "\n",
    "\n",
    "function train(; kws...)\n",
    "    args = Args(; kws...) # collect options in a struct for convenience\n",
    "\n",
    "    @info \"Getting data...\"\n",
    "    \n",
    "    train_loader, test_loader = get_data(args)\n",
    "\n",
    "    model = set_model() # my implmentation\n",
    "    # model = alexnet() # Metalhead's implmentation\n",
    "    # model = LeNet5() # test pipeline\n",
    "\n",
    "\n",
    "    ps = Flux.params(model)  \n",
    "    opt = ADAM(args.η) \n",
    "\n",
    "    @info \"Start training...\"\n",
    "\n",
    "    for epoch in 1:args.epochs\n",
    "\n",
    "        for (x,y) in ProgressBar(train_loader)\n",
    "            @assert size(x) == (64, 64, 3, args.batchsize) \n",
    "            @assert size(y) == (10, args.batchsize) \n",
    "\n",
    "            gs = gradient(() -> loss_function(model(x), y), ps) \n",
    "            Flux.Optimise.update!(opt, ps, gs)\n",
    "        end\n",
    "\n",
    "        train = evaluation_loss_accuracy(train_loader, model)\n",
    "        test = evaluation_loss_accuracy(test_loader, model)\n",
    "\n",
    "        println(\"Epoch $(epoch-1)\")\n",
    "        println(\"\\t Train => loss = $(train[1]) \\t acc = $(train[2])\")\n",
    "        println(\"\\t Test => loss = $(test[1]) \\t acc = $(test[2])\")\n",
    "    \n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "if abspath(PROGRAM_FILE) == @__FILE__\n",
    "    train()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d1a0be-39ac-4ca8-96bc-c8a110c3ce1d",
   "metadata": {},
   "source": [
    "# References\n",
    "- [ ] [alexnet-cifar10-julia](https://github.com/francescodisalvo05/alexnet-cifar10-julia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b554a5-2894-4809-ad34-dce63110afdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
