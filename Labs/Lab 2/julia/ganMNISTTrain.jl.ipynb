{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd61a1c7-56f7-4c1c-ae35-6bf9f20e99ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, MLDatasets, Statistics, Random, BSON\n",
    "using Flux.Optimise: update!\n",
    "using Flux: logitbinarycrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c26e4b92-f871-4074-b19e-ca2c54d37ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mUsing backend: Metal.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AGXG14GDevice: 0x1562bd800>\n",
       "    name = Apple M2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Metal\n",
    "\n",
    "Metal.functional()\n",
    "device = Flux.get_device(; verbose=true)\n",
    "device.deviceID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6214963-7505-45f2-96d6-44a2a5b64166",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize, latentDim = 500, 100\n",
    "epochs = 40\n",
    "etaD, etaG = 0.0002, 0.0002;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54b2baac-50a5-4ea9-b99a-1da38a28b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, _ = MLDatasets.MNIST.traindata(Float32)\n",
    "images, _ = MNIST(split=:train)[:]\n",
    "imageTensor = reshape(@.(2f0 * images - 1f0), 28, 28, 1, :)\n",
    "data = [imageTensor[:, :, :, r] for r in Iterators.partition(1:60000, batchSize)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "facfe97c-6c7d-4e32-a7e4-e01cd070b600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(100 => 12544),                  \u001b[90m# 1_266_944 parameters\u001b[39m\n",
       "  BatchNorm(12544, relu),               \u001b[90m# 25_088 parameters\u001b[39m\u001b[90m, plus 25_088\u001b[39m\n",
       "  var\"#9#10\"(),\n",
       "  ConvTranspose((5, 5), 256 => 128, pad=2),  \u001b[90m# 819_328 parameters\u001b[39m\n",
       "  BatchNorm(128, relu),                 \u001b[90m# 256 parameters\u001b[39m\u001b[90m, plus 256\u001b[39m\n",
       "  ConvTranspose((4, 4), 128 => 64, pad=1, stride=2),  \u001b[90m# 131_136 parameters\u001b[39m\n",
       "  BatchNorm(64, relu),                  \u001b[90m# 128 parameters\u001b[39m\u001b[90m, plus 128\u001b[39m\n",
       "  ConvTranspose((4, 4), 64 => 1, tanh, pad=1, stride=2),  \u001b[90m# 1_025 parameters\u001b[39m\n",
       ") \u001b[90m        # Total: 14 trainable arrays, \u001b[39m2_243_905 parameters,\n",
       "\u001b[90m          # plus 6 non-trainable, 25_472 parameters, summarysize \u001b[39m8.659 MiB."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dscr = Chain(Conv((4,4),1=>64;stride=2,pad=1),x->leakyrelu.(x,0.2f0),\n",
    "        Dropout(0.25),Conv((4,4),64=>128;stride=2,pad=1),x->leakyrelu.(x,0.2f0),\n",
    "        Dropout(0.25), x->reshape(x, 7 * 7 * 128, :), Dense(7 * 7 * 128, 1))\n",
    "gen =  Chain(Dense(latentDim,7*7*256),BatchNorm(7*7*256,relu),\n",
    "        x->reshape(x,7,7,256,:),ConvTranspose((5,5),256=>128;stride=1,pad=2),\n",
    "        BatchNorm(128,relu),ConvTranspose((4,4),128=>64;stride=2,pad=1),\n",
    "        BatchNorm(64,relu),ConvTranspose((4,4),64=>1,tanh;stride=2,pad=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae27d082-fca9-4c1b-97c2-ac6a0ac46e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dLoss(realOut,fakeOut) =    mean(logitbinarycrossentropy.(realOut,1f0)) +\n",
    "                            mean(logitbinarycrossentropy.(fakeOut,0f0))\n",
    "gLoss(u) = mean(logitbinarycrossentropy.(u, 1f0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fa31b5c-0300-4158-97fc-90714ac2e195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "updateD! (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function updateD!(gen, dscr, x, opt_dscr)\n",
    "    noise = randn!(similar(x, (latentDim, batchSize)))\n",
    "    fakeInput = gen(noise)\n",
    "    ps = Flux.params(dscr)\n",
    "    loss, back = Flux.pullback(()->dLoss(dscr(x), dscr(fakeInput)), ps)\n",
    "    grad = back(1f0)\n",
    "    update!(opt_dscr, ps, grad)\n",
    "    return loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0037a061-c3f3-4fbc-8484-b3fc504d4e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "updateG! (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function updateG!(gen, dscr, x, optGen)\n",
    "    noise = randn!(similar(x, (latentDim, batchSize)))\n",
    "    ps = Flux.params(gen)\n",
    "    loss, back = Flux.pullback(()->gLoss(dscr(gen(noise))),ps)\n",
    "    grad = back(1f0)\n",
    "    update!(optGen, ps, grad)\n",
    "    return loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a85cc4d-d888-49d1-853d-a6bb346bdbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 1, D loss = 1.3860536, G loss = 0.68386394\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 2, D loss = 1.2977568, G loss = 0.633849\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 3, D loss = 1.2196785, G loss = 0.58668965\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 4, D loss = 1.1495194, G loss = 0.54042566\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 5, D loss = 1.0852562, G loss = 0.49773306\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 6, D loss = 1.031728, G loss = 0.45863298\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 7, D loss = 0.9815934, G loss = 0.41732886\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 8, D loss = 0.9550576, G loss = 0.37962782\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 9, D loss = 0.9315155, G loss = 0.34747088\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 10, D loss = 0.9339678, G loss = 0.3159576\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 11, D loss = 0.9433363, G loss = 0.29026943\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 12, D loss = 0.9674238, G loss = 0.26801458\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 13, D loss = 1.0143936, G loss = 0.24936058\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 14, D loss = 1.0633826, G loss = 0.23654398\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 15, D loss = 1.1249213, G loss = 0.22828664\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 16, D loss = 1.1884801, G loss = 0.22346593\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 17, D loss = 1.2436775, G loss = 0.22431906\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 18, D loss = 1.2882612, G loss = 0.22968368\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 19, D loss = 1.3170323, G loss = 0.23626567\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 20, D loss = 1.3273681, G loss = 0.24703482\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 21, D loss = 1.3263849, G loss = 0.26276907\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 22, D loss = 1.3056847, G loss = 0.27753156\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 23, D loss = 1.2874895, G loss = 0.29528698\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 24, D loss = 1.256071, G loss = 0.3130951\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 25, D loss = 1.2247641, G loss = 0.3319563\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 26, D loss = 1.1943926, G loss = 0.35324508\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 27, D loss = 1.1606746, G loss = 0.37569556\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 28, D loss = 1.1337706, G loss = 0.39401248\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 29, D loss = 1.1103712, G loss = 0.41538948\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 30, D loss = 1.1097231, G loss = 0.4346642\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 31, D loss = 1.0970148, G loss = 0.45619568\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 32, D loss = 1.0997343, G loss = 0.47129858\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 33, D loss = 1.0993677, G loss = 0.49226147\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 34, D loss = 1.1282451, G loss = 0.50866693\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 35, D loss = 1.1461229, G loss = 0.5241444\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 36, D loss = 1.193496, G loss = 0.53698885\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 37, D loss = 1.2247415, G loss = 0.54544\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 38, D loss = 1.2645559, G loss = 0.54906\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 39, D loss = 1.3001535, G loss = 0.555137\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 40, D loss = 1.3430499, G loss = 0.5552954\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 41, D loss = 1.400187, G loss = 0.55237556\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 42, D loss = 1.4297465, G loss = 0.54552966\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 43, D loss = 1.4765804, G loss = 0.5373444\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 44, D loss = 1.5106454, G loss = 0.5186436\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 45, D loss = 1.5549079, G loss = 0.5020954\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 46, D loss = 1.5540462, G loss = 0.4951807\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 47, D loss = 1.5547367, G loss = 0.5092633\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 48, D loss = 1.5479987, G loss = 0.52592266\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 49, D loss = 1.5006592, G loss = 0.56038064\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 50, D loss = 1.4755361, G loss = 0.5931168\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 51, D loss = 1.4321053, G loss = 0.6303942\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 52, D loss = 1.3970008, G loss = 0.6584336\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 53, D loss = 1.3427343, G loss = 0.69187516\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 54, D loss = 1.3168199, G loss = 0.718258\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 55, D loss = 1.2864419, G loss = 0.74026674\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 56, D loss = 1.24104, G loss = 0.7650739\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 57, D loss = 1.2035664, G loss = 0.78447276\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 58, D loss = 1.1747003, G loss = 0.8043027\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 59, D loss = 1.1279116, G loss = 0.8273591\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 60, D loss = 1.0830181, G loss = 0.8499257\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 61, D loss = 1.0617765, G loss = 0.8648971\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 62, D loss = 1.0122269, G loss = 0.88615394\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 63, D loss = 0.9855074, G loss = 0.8973937\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 64, D loss = 0.9540781, G loss = 0.91559976\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 65, D loss = 0.94340014, G loss = 0.9195925\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 66, D loss = 0.91834444, G loss = 0.9233661\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 67, D loss = 0.9108014, G loss = 0.92497724\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 68, D loss = 0.8930154, G loss = 0.92350715\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 69, D loss = 0.900543, G loss = 0.92642677\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 70, D loss = 0.9063225, G loss = 0.91778815\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 71, D loss = 0.92076033, G loss = 0.89477926\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 72, D loss = 0.9393786, G loss = 0.8779925\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 73, D loss = 0.9709761, G loss = 0.85497487\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 74, D loss = 0.99729085, G loss = 0.8219899\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 75, D loss = 1.0495149, G loss = 0.78784496\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 76, D loss = 1.0875704, G loss = 0.75488615\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 77, D loss = 1.1259692, G loss = 0.7298222\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 78, D loss = 1.1620253, G loss = 0.7139554\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 79, D loss = 1.1979069, G loss = 0.6983321\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 80, D loss = 1.2097057, G loss = 0.6918278\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 81, D loss = 1.2379194, G loss = 0.68722355\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 82, D loss = 1.2650911, G loss = 0.6851477\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 83, D loss = 1.293869, G loss = 0.67671514\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 84, D loss = 1.290756, G loss = 0.6743211\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 85, D loss = 1.3184382, G loss = 0.6723249\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 86, D loss = 1.3164904, G loss = 0.6719188\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 87, D loss = 1.3085313, G loss = 0.6656056\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 88, D loss = 1.3046042, G loss = 0.6759833\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 89, D loss = 1.3154857, G loss = 0.68457067\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 90, D loss = 1.2870569, G loss = 0.686019\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 91, D loss = 1.2990649, G loss = 0.68394005\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 92, D loss = 1.2983109, G loss = 0.66925865\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 93, D loss = 1.3085394, G loss = 0.66122293\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 94, D loss = 1.2950314, G loss = 0.6570626\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 95, D loss = 1.2774386, G loss = 0.6601007\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 96, D loss = 1.2570605, G loss = 0.68441427\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 97, D loss = 1.2227848, G loss = 0.71382546\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 98, D loss = 1.1959257, G loss = 0.7449538\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 99, D loss = 1.2020067, G loss = 0.76971513\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 100, D loss = 1.1991268, G loss = 0.7891644\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 101, D loss = 1.1677394, G loss = 0.8050791\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 102, D loss = 1.1825448, G loss = 0.81577444\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 103, D loss = 1.1833158, G loss = 0.8179008\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 104, D loss = 1.2078803, G loss = 0.8164575\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 105, D loss = 1.2017426, G loss = 0.8041035\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 106, D loss = 1.2041116, G loss = 0.8107298\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 107, D loss = 1.2293928, G loss = 0.79518974\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 108, D loss = 1.2545395, G loss = 0.797145\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 109, D loss = 1.2629783, G loss = 0.79682237\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 110, D loss = 1.2805977, G loss = 0.8073085\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 111, D loss = 1.278692, G loss = 0.8163772\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 112, D loss = 1.2561576, G loss = 0.83967865\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 113, D loss = 1.2530785, G loss = 0.8750016\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 114, D loss = 1.2504323, G loss = 0.9126793\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 115, D loss = 1.1969688, G loss = 0.9681006\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 116, D loss = 1.1465015, G loss = 1.01881\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 117, D loss = 1.0597383, G loss = 1.0987092\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 118, D loss = 0.97252464, G loss = 1.1550994\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 119, D loss = 0.88705766, G loss = 1.225125\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch 1, batch 120, D loss = 0.8275645, G loss = 1.3053364\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mSaving generator for epcoh 1\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `params` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `params` not defined",
      "",
      "Stacktrace:",
      " [1] macro expansion",
      "   @ ./In[9]:11 [inlined]",
      " [2] macro expansion",
      "   @ ./timing.jl:279 [inlined]",
      " [3] top-level scope",
      "   @ ./In[9]:3"
     ]
    }
   ],
   "source": [
    "optDscr, optGen = ADAM(etaD), ADAM(etaG)\n",
    "cd(@__DIR__)\n",
    "@time begin\n",
    "    for ep in 1:epochs\n",
    "        for (bi,x) in enumerate(data)\n",
    "            lossD = updateD!(gen, dscr, x, optDscr)\n",
    "            lossG = updateG!(gen, dscr, x, optGen)\n",
    "            @info \"Epoch $ep, batch $bi, D loss = $(lossD), G loss = $(lossG)\"\n",
    "        end\n",
    "        @info \"Saving generator for epcoh $ep\"\n",
    "        BSON.@save \"../data/mnistGAN$(ep).bson\" genParams=cpu.(params(gen))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffa9675-568f-458c-8aed-80adae83a0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
