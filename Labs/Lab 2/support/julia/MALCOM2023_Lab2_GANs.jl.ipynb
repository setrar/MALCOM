{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Session 2\n",
    "# Generative Adversarial Networks (GANs)\n",
    "\n",
    "In this lab session, we will explore **generative models** and in particular, we will build a Generative Adversarial Network. GANs are basically neural networks that learn to generate samples (synthetic data) that are very similar to some input data. In this exercise, we build and train a simple GAN that can generate new images (handwritten digits) that resemble a set of training images (taken from MNIST dataset). In a way, we are teaching a neural network how to write.\n",
    "\n",
    "### Recap on GANs\n",
    "\n",
    "GANs consist of two different neural networks (models). \n",
    "The first network is called the **discriminator** and is a standard binary classifier that determines whether an image looks like a real one (taken from the dataset) or a fake one (not present in the training set). \n",
    "The second network is called the **generator**. It takes random noise as input and transforms it into images using a neural network. The goal of the generator is to fool the discriminator into thinking the images it produced are real.\n",
    "\n",
    "The continuous process of the generator ($G$) trying to fool the discriminator ($D$), and the discriminator trying to correctly classify real vs. fake can be described as a minimax game:\n",
    "$$\\underset{G}{\\text{min}}\\; \\underset{D}{\\text{max}}\\; \\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] + \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
    "where $x \\sim p_\\text{data}$ are samples from the input data, $z \\sim p(z)$ are the random noise samples, $G(z)$ are the generated images using the neural network generator $G$, and $D$ is the output of the discriminator, specifying the probability of an input being real. This minimax game is shown to be related to minimizing the Jensen-Shannon divergence between the training data distribution and the generated samples from $G$.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "To optimize this minimax game, we alternate between taking gradient descent steps on the objective for $G$, and gradient ascent steps on the objective for $D$:\n",
    "1. update $G$ to minimize the probability of the __discriminator making the correct choice__. \n",
    "2. update $D$ to maximize the probability of the __discriminator making the correct choice__.\n",
    "\n",
    "As we discussed during the lecture, we update the generator as maximizing the probability of the **discriminator making the incorrect choice**. That way, we alleviate the vanishing gradient problem of the generator. Therefore, in this exercise, we alternate the following updates:\n",
    "1. Update $G$ to maximize the probability of the discriminator making the incorrect choice on generated data:\n",
    "$$\\underset{G}{\\text{max}}\\;  \\mathbb{E}_{z \\sim p(z)}\\left[\\log D(G(z))\\right]$$\n",
    "2. Update $D$, to maximize the probability of the discriminator making the correct choice on real and generated data:\n",
    "$$\\underset{D}{\\text{max}}\\; \\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] + \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
    "\n",
    "\n",
    "### Lab Session Objective and Output: \n",
    "You will need to complete the notebooks by performing all tasks (7 implementation tasks and 2 questions related to a qualitative assessment of your results)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using Flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset (MNIST data)\n",
    "For simplicity and computational convenience, we use the MNIST dataset. This dataset contains real handwritten digits and 70,000 images of handwritten digits compiled by the U.S. National Institute of Standards and Technology from Census Bureau employees and high school students. Each picture contains a centered image of white digit on black background (0 through 9). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a batch\n",
    "# mnist = MNIST(batch_size=16) \n",
    "# show_images(mnist.X[:16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Function\n",
    "We implement below the neural network function. To avoid potential issues from ReLU, we will implement Leaky ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "leaky_relu (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function leaky_relu(x; alpha=0.01)\n",
    "    # Compute the leaky ReLU activation function\n",
    "    # Inputs:\n",
    "    # - x: Julia Array with arbitrary shape\n",
    "    # - alpha: leak parameter for leaky ReLU\n",
    "    # Output:\n",
    "    # - y: a Julia Array with the same shape as x\n",
    "\n",
    "    # TASK 1 TODO: Implement a leaky ReLU activation function\n",
    "    # Element-wise maximum operation\n",
    "    y = max.(x, alpha .* x)  # Using broadcasting for element-wise operations\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Noise\n",
    "In the cell below, we will generate a random uniform noise from -1 to 1 with shape `[batch_size, dim]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "random_noise (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random\n",
    "\n",
    "function random_noise(batch_size, dim)\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - batch_size: integer giving the batch size of noise to generate\n",
    "    - dim: integer giving the dimension of the noise to generate\n",
    "    Output:\n",
    "    - noise: a Julia Array containing uniform noise in [-1, 1] with shape (batch_size, dim)\n",
    "    \"\"\"\n",
    "\n",
    "    # Task 2 TODO: sample from and return random noise (uniform)\n",
    "    noise = 2 * rand(batch_size, dim) .- 1  # Generate uniform noise from [-1, 1]\n",
    "    return noise\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "First, we will implement the first neural network, the discriminator. To build the model, we will use the layers in `tf.layers`. The architecture we adopt is as follows:\n",
    " * Fully connected layer from size 784 to 256\n",
    " * LeakyReLU with alpha 0.01\n",
    " * Fully connected layer from 256 to 256\n",
    " * LeakyReLU with alpha 0.01\n",
    " * Fully connected layer from 256 to 1\n",
    " \n",
    "The output of the discriminator should have shape `[batch_size, 1]`, and should contain real numbers corresponding to the scores that each of the `batch_size` inputs is a real image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discriminator (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function discriminator(x)\n",
    "    # Create the model using Flux's Chain\n",
    "    model = Chain(\n",
    "        Dense(784, 256), # Fully connected layer from 784 to 256\n",
    "        x -> leakyrelu(x, 0.01), # LeakyReLU with alpha 0.01\n",
    "        Dense(256, 256), # Fully connected layer from 256 to 256\n",
    "        x -> leakyrelu(x, 0.01), # LeakyReLU with alpha 0.01\n",
    "        Dense(256, 1) # Fully connected layer from 256 to 1\n",
    "    )\n",
    "\n",
    "    # Apply the model to the input x\n",
    "    logits = model(x)\n",
    "\n",
    "    return logits\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# x = rand(Float32, 784, 64) # Random batch of 64 images, each flattened to 784\n",
    "# logits = discriminator(x)\n",
    "# println(size(logits)) # Should print (1, 64) as the output size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "Second, we will build the generator in a similar way as the discriminator. The architecure we adopt is:\n",
    " * Fully connected layer from tf.shape(z)[1] (the number of noise dimensions) to 1024\n",
    " * ReLU\n",
    " * Fully connected layer from 1024 to 1024 \n",
    " * ReLU\n",
    " * Fully connected layer from 1024 to 784\n",
    " * Tanh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function generator(z)\n",
    "    # Create the model using Flux's Chain\n",
    "    model = Chain(\n",
    "        Dense(size(z, 2), 1024), # Fully connected layer from noise dimension to 1024\n",
    "        Flux.relu, # ReLU activation function\n",
    "        Dense(1024, 1024), # Fully connected layer from 1024 to 1024\n",
    "        Flux.relu, # ReLU activation function\n",
    "        Dense(1024, 784), # Fully connected layer from 1024 to 784\n",
    "        tanh # Tanh activation function to scale the output between -1 and 1\n",
    "    )\n",
    "\n",
    "    # Apply the model to the input z\n",
    "    img = model(z)\n",
    "\n",
    "    return img\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# z = randn(Float32, 64, 100) # Random batch of 64 noise vectors, each of 100 dimensions\n",
    "# img = generator(z)\n",
    "# println(size(img)) # Should print (784, 64) as the output size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Loss\n",
    "\n",
    "We will implement below the loss of the GAN. \n",
    "\n",
    "The generator loss is:\n",
    "\n",
    "$$\\mathcal{L}_G  =  -\\mathbb{E}_{z \\sim p(z)}\\left[\\log D(G(z))\\right]$$\n",
    "\n",
    "The discriminator loss is:\n",
    "\n",
    "$$\\mathcal{L}_D = -\\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] - \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
    "\n",
    "For computing the loss function, we will use the sigmoid cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gan_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gan_loss(logits_real, logits_fake)\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - logits_real: Array, shape [batch_size, 1], output of discriminator\n",
    "        Log probability that the image is real for each real image\n",
    "    - logits_fake: Array, shape [batch_size, 1], output of discriminator\n",
    "        Log probability that the image is real for each fake image\n",
    "    \n",
    "    Outputs:\n",
    "    - D_loss: discriminator loss [scalar]\n",
    "    - G_loss: generator loss [scalar]\n",
    "    \"\"\"\n",
    "\n",
    "    # Using Flux's binary cross entropy loss with logit (automatically applies sigmoid)\n",
    "    # Discriminator loss - Real images should be classified as real\n",
    "    D_loss_real = mean(Flux.binarycrossentropy.(logits_real, ones(size(logits_real))))\n",
    "    # Discriminator loss - Fake images should be classified as fake\n",
    "    D_loss_fake = mean(Flux.binarycrossentropy.(logits_fake, zeros(size(logits_fake))))\n",
    "    # Total discriminator loss\n",
    "    D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "    # Generator loss - Generator aims for discriminator to classify fake images as real\n",
    "    G_loss = mean(Flux.binarycrossentropy.(logits_fake, ones(size(logits_fake))))\n",
    "\n",
    "    return D_loss, G_loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# batch_size = 64\n",
    "# logits_real = randn(Float32, batch_size, 1)  # Random discriminator outputs for real images\n",
    "# logits_fake = randn(Float32, batch_size, 1)  # Random discriminator outputs for fake images\n",
    "\n",
    "# D_loss, G_loss = gan_loss(logits_real, logits_fake)\n",
    "# println(\"Discriminator Loss: $D_loss, Generator Loss: $G_loss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer\n",
    "For the loss optimization, we will implement an `AdamOptimizer` with a 1e-3 learning rate, beta1=0.5 to mininize G_loss and D_loss separately. If you want to see a 'pathological' mode in GANs, you can beta1=0.9. That way, the discriminator loss might go to zero (i.e., learns too fast) and the generator might fail completely to learn. \n",
    "You can also experiment with other optimizers (e.g., SGD with Momentum or RMSProp). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gan_optimizers (generic function with 3 methods)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 6 TODO: Implement an AdamOptimizer for D_opt and G_opt\n",
    "function gan_optimizers(learning_rate=1e-3, beta1=0.5)\n",
    "    \"\"\"\n",
    "    Create optimizers for GAN training.\n",
    "    Inputs:\n",
    "    - learning_rate: learning rate to use for both optimizers\n",
    "    - beta1: beta parameter for both optimizers (first moment decay)\n",
    "    \n",
    "    Outputs:\n",
    "    - D_opt: instance of Flux.Optimise.ADAM with correct learning_rate and beta1\n",
    "    - G_opt: instance of Flux.Optimise.ADAM with correct learning_rate and beta1\n",
    "    \"\"\"\n",
    "    \n",
    "    # The default value for beta2 in ADAM in Flux is 0.999 which is commonly used\n",
    "    D_opt = ADAM(learning_rate, (beta1, 0.999))\n",
    "    G_opt = ADAM(learning_rate, (beta1, 0.999))\n",
    "\n",
    "    return D_opt, G_opt\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# D_opt, G_opt = gan_optimizers(1e-3, 0.5)\n",
    "# println(\"Discriminator Optimizer: \", D_opt)\n",
    "# println(\"Generator Optimizer: \", G_opt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Composition\n",
    "In the below cell, we compose the generator and discriminator by using the previous functions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "using Flux\n",
    "using Random\n",
    "\n",
    "# Define the generator and discriminator using previously discussed setups\n",
    "function generator(z)\n",
    "    model = Chain(\n",
    "        Dense(size(z, 2), 1024),\n",
    "        relu,\n",
    "        Dense(1024, 1024),\n",
    "        relu,\n",
    "        Dense(1024, 784),\n",
    "        tanh\n",
    "    )\n",
    "    return model(z)\n",
    "end\n",
    "\n",
    "function discriminator(x)\n",
    "    model = Chain(\n",
    "        Dense(784, 256),\n",
    "        x -> leakyrelu(x, 0.01),\n",
    "        Dense(256, 256),\n",
    "        x -> leakyrelu(x, 0.01),\n",
    "        Dense(256, 1)\n",
    "    )\n",
    "    return model(x)\n",
    "end\n",
    "\n",
    "# Parameters\n",
    "batch_size = 128\n",
    "noise_dim = 96\n",
    "\n",
    "# Generate noise input for the generator\n",
    "function random_noise(batch_size, noise_dim)\n",
    "    return 2 * rand(Float32, noise_dim, batch_size) .- 1\n",
    "end\n",
    "\n",
    "# Loss functions and optimizers\n",
    "function gan_loss(logits_real, logits_fake)\n",
    "    D_loss_real = mean(Flux.logitbinarycrossentropy.(logits_real, ones(size(logits_real))))\n",
    "    D_loss_fake = mean(Flux.logitbinarycrossentropy.(logits_fake, zeros(size(logits_fake))))\n",
    "    D_loss = D_loss_real + D_loss_fake\n",
    "    G_loss = mean(Flux.logitbinarycrossentropy.(logits_fake, ones(size(logits_fake))))\n",
    "    return D_loss, G_loss\n",
    "end\n",
    "\n",
    "function gan_optimizers(learning_rate=1e-3, beta1=0.5)\n",
    "    D_opt = ADAM(learning_rate, (beta1, 0.999))\n",
    "    G_opt = ADAM(learning_rate, (beta1, 0.999))\n",
    "    return D_opt, G_opt\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "DimensionMismatch: layer Dense(96 => 1024) expects size(input, 1) == 96, but got 128×96 Matrix{Float64}",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch: layer Dense(96 => 1024) expects size(input, 1) == 96, but got 128×96 Matrix{Float64}",
      "",
      "Stacktrace:",
      " [1] _size_check(layer::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, x::Matrix{Float64}, ::Pair{Int64, Int64})",
      "   @ Flux ~/.julia/packages/Flux/Wz6D4/src/layers/basic.jl:195",
      " [2] (::Dense{typeof(identity), Matrix{Float32}, Vector{Float32}})(x::Matrix{Float64})",
      "   @ Flux ~/.julia/packages/Flux/Wz6D4/src/layers/basic.jl:171",
      " [3] macro expansion",
      "   @ ~/.julia/packages/Flux/Wz6D4/src/layers/basic.jl:53 [inlined]",
      " [4] _applychain(layers::Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(relu), Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(relu), Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(tanh)}, x::Matrix{Float64})",
      "   @ Flux ~/.julia/packages/Flux/Wz6D4/src/layers/basic.jl:53",
      " [5] (::Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(relu), Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(relu), Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, typeof(tanh)}})(x::Matrix{Float64})",
      "   @ Flux ~/.julia/packages/Flux/Wz6D4/src/layers/basic.jl:51",
      " [6] generator(z::Matrix{Float64})",
      "   @ Main ./In[7]:13",
      " [7] top-level scope",
      "   @ In[13]:8"
     ]
    }
   ],
   "source": [
    "# number of images for each batch\n",
    "batch_size = 128\n",
    "# random noise dimension\n",
    "noise_dim = 96\n",
    "\n",
    "# Initialize models\n",
    "z = random_noise(batch_size, noise_dim)\n",
    "G_sample = generator(z)\n",
    "\n",
    "# Mock `x` input representing training data\n",
    "x = rand(Float32, 784, batch_size)\n",
    "\n",
    "# Evaluate discriminator outputs\n",
    "logits_real = discriminator(2 * x .- 1.0)\n",
    "logits_fake = discriminator(G_sample)\n",
    "\n",
    "# Get optimizers and losses\n",
    "D_opt, G_opt = gan_optimizers()\n",
    "D_loss, G_loss = gan_loss(logits_real, logits_fake)\n",
    "\n",
    "# Training steps\n",
    "ps = Flux.params(G_sample) # Collect parameters from the generator\n",
    "D_train_step = () -> Flux.train!(D_loss, ps, data, D_opt)\n",
    "G_train_step = () -> Flux.train!(G_loss, ps, data, G_opt)\n",
    "\n",
    "# Simulating training steps\n",
    "data = [(x, G_sample)] # Mock data tuple for training\n",
    "\n",
    "for i in 1:10  # Training loop for demonstration\n",
    "    D_train_step()\n",
    "    G_train_step()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show_images (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function show_images(images; img_size=(28, 28), nrows=4, ncols=4)\n",
    "    # Function to plot images in a grid, assumes images are flattened\n",
    "    images = reshape(images, img_size..., size(images, 2))\n",
    "    p = plot(size=(600, 600), layout=(nrows, ncols), color=:gray)\n",
    "    for i in 1:nrows*ncols\n",
    "        plot!(p[i], images[:, :, i], seriestype=:heatmap, yflip=true, axis=nothing)\n",
    "    end\n",
    "    display(p)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to train our GAN!\n",
    "It is not time to start training our GAN. We use a simple procedure. We train D(x) and G(z) with one batch each every iteration. Training could take several minutes if run on a CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_a_gan (generic function with 5 methods)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function run_a_gan(G_train_step, G_loss, D_train_step, D_loss, \n",
    "                   show_every=2, print_every=1, batch_size=128, num_epoch=10)\n",
    "    # Load MNIST data\n",
    "    train_x, _ = MLDatasets.MNIST.traindata(Float32)\n",
    "    train_x = reshape(train_x, 28 * 28, :)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in 1:num_epoch\n",
    "        if epoch % show_every == 0\n",
    "            z = random_noise(batch_size, noise_dim)  # noise_dim must be defined globally or passed\n",
    "            samples = generator(z)\n",
    "            show_images(samples[:, 1:16])\n",
    "        end\n",
    "\n",
    "        # Iterate over the dataset\n",
    "        for i in 1:batch_size:size(train_x, 2)-batch_size\n",
    "            minibatch = train_x[:, i:i+batch_size-1]\n",
    "            x = minibatch * 2 .- 1  # Scale images to [-1, 1]\n",
    "            z = random_noise(batch_size, noise_dim)\n",
    "\n",
    "            # Update Discriminator\n",
    "            Flux.train!(D_loss, params(D_train_step), [(minibatch,)], D_opt)\n",
    "\n",
    "            # Update Generator\n",
    "            Flux.train!(G_loss, params(G_train_step), [(z,)], G_opt)\n",
    "        end\n",
    "\n",
    "        if epoch % print_every == 0\n",
    "            @info \"Epoch: $epoch, D: $(mean(D_loss)), G: $(mean(G_loss))\"\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Final images display\n",
    "    z = random_noise(batch_size, noise_dim)\n",
    "    samples = generator(z)\n",
    "    show_images(samples[:, 1:16])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `G_train_step` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `G_train_step` not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[16]:8"
     ]
    }
   ],
   "source": [
    "# Specify the number of epochs directly in the function call or handle it inside the function\n",
    "num_epochs = 10\n",
    "batch_size = 128  # Specify your batch size\n",
    "print_every = 1\n",
    "show_every = 2\n",
    "\n",
    "# Call the GAN training function\n",
    "run_a_gan(G_train_step, G_loss, D_train_step, D_loss,\n",
    "          show_every=show_every, print_every=print_every, batch_size=batch_size, num_epoch=num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN2: Changing the loss function and the divergence \n",
    "We will now implement a GAN with a different loss function. Specifically, we will implement the following objective functions for \n",
    "the generator loss:\n",
    "$$\\mathcal{L}_G  =  \\frac{1}{2}\\mathbb{E}_{z \\sim p(z)}\\left[\\left(D(G(z))-1\\right)^2\\right]$$\n",
    "and the discriminator loss:\n",
    "$$ \\mathcal{L}_D = \\frac{1}{2}\\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\left(D(x)-1\\right)^2\\right] + \\frac{1}{2}\\mathbb{E}_{z \\sim p(z)}\\left[ \\left(D(G(z))\\right)^2\\right]$$\n",
    "This GAN variant is known as Least Squares GAN, which substitutes the binary cross entropy loss with a least square ($\\ell_2$) loss, which has better properties for optimization and is less likely to saturate. It has been shown that minimizing the above objective functions yields minimizing the Pearson $\\chi^2$ divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gan2_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux\n",
    "\n",
    "function gan2_loss(score_real, score_fake)\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - score_real: Array, shape [batch_size, 1], output of discriminator scoring real images\n",
    "    - score_fake: Array, shape [batch_size, 1], output of discriminator scoring fake images\n",
    "    \n",
    "    Outputs:\n",
    "    - D_loss: discriminator loss (scalar)\n",
    "    - G_loss: generator loss (scalar)\n",
    "    \"\"\"\n",
    "\n",
    "    # Using sigmoid cross-entropy loss functions\n",
    "    D_loss_real = Flux.binarycrossentropy.(Flux.σ.(score_real), ones(size(score_real)))\n",
    "    D_loss_fake = Flux.binarycrossentropy.(Flux.σ.(score_fake), zeros(size(score_fake)))\n",
    "    \n",
    "    # Discriminator loss combines real loss and fake loss\n",
    "    D_loss = mean(D_loss_real) + mean(D_loss_fake)\n",
    "    \n",
    "    # Generator tries to fool the discriminator, so it tries to increase the mistake on fake images\n",
    "    G_loss = mean(Flux.binarycrossentropy.(Flux.σ.(score_fake), ones(size(score_fake))))\n",
    "\n",
    "    return D_loss, G_loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example use-case:\n",
    "# batch_size = 128\n",
    "# score_real = randn(Float32, batch_size, 1)  # Simulated scores for real images\n",
    "# score_fake = randn(Float32, batch_size, 1)  # Simulated scores for fake images\n",
    "\n",
    "# D_loss, G_loss = gan2_loss(score_real, score_fake)\n",
    "# println(\"Discriminator Loss: \", D_loss, \", Generator Loss: \", G_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new training steps to minimize the new GAN loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ParseError:\n\u001b[90m# Error @ \u001b[0;0m\u001b]8;;file:///Users/valiha/Developer/MALCOM/Labs/Lab 2/In[19]#7:23\u001b\\\u001b[90mIn[19]:7:23\u001b[0;0m\u001b]8;;\u001b\\\n# Assuming you have your models (discriminator and generator)\ndiscriminator_model = \u001b[48;2;120;70;70m...\u001b[0;0m  # Your discriminator model definition\n\u001b[90m#                     └─┘ ── \u001b[0;0m\u001b[91minvalid identifier\u001b[0;0m",
     "output_type": "error",
     "traceback": [
      "ParseError:\n\u001b[90m# Error @ \u001b[0;0m\u001b]8;;file:///Users/valiha/Developer/MALCOM/Labs/Lab 2/In[19]#7:23\u001b\\\u001b[90mIn[19]:7:23\u001b[0;0m\u001b]8;;\u001b\\\n# Assuming you have your models (discriminator and generator)\ndiscriminator_model = \u001b[48;2;120;70;70m...\u001b[0;0m  # Your discriminator model definition\n\u001b[90m#                     └─┘ ── \u001b[0;0m\u001b[91minvalid identifier\u001b[0;0m",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[19]:7"
     ]
    }
   ],
   "source": [
    "# Assuming that D_loss and G_loss are already computed using previously defined gan2_loss function\n",
    "# Assuming that D_opt and G_opt are instances of optimizers, for example, created using ADAM\n",
    "# Assuming logits_real and logits_fake are outputs from your discriminator\n",
    "\n",
    "# Define models and load parameters\n",
    "# Assuming you have your models (discriminator and generator)\n",
    "discriminator_model = ...  # Your discriminator model definition\n",
    "generator_model = ...  # Your generator model definition\n",
    "\n",
    "# Collect parameters from both models\n",
    "D_vars = params(discriminator_model)  # Collects all trainable parameters in the discriminator\n",
    "G_vars = params(generator_model)      # Collects all trainable parameters in the generator\n",
    "\n",
    "# Function to update the discriminator\n",
    "function D_train_step()\n",
    "    grads = gradient(() -> D_loss, D_vars)\n",
    "    Flux.Optimise.update!(D_opt, D_vars, grads)\n",
    "end\n",
    "\n",
    "# Function to update the generator\n",
    "function G_train_step()\n",
    "    grads = gradient(() -> G_loss, G_vars)\n",
    "    Flux.Optimise.update!(G_opt, G_vars, grads)\n",
    "end\n",
    "\n",
    "# Example call to training functions within a training loop\n",
    "for epoch in 1:10\n",
    "    # Update Discriminator\n",
    "    D_train_step()\n",
    "\n",
    "    # Update Generator\n",
    "    G_train_step()\n",
    "\n",
    "    # Optionally print losses or validate here\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below cell to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching generator()\n\n\u001b[0mClosest candidates are:\n\u001b[0m  generator(\u001b[91m::Any\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mMain\u001b[39m \u001b[90m\u001b[4mIn[7]:1\u001b[24m\u001b[39m\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching generator()\n\n\u001b[0mClosest candidates are:\n\u001b[0m  generator(\u001b[91m::Any\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mMain\u001b[39m \u001b[90m\u001b[4mIn[7]:1\u001b[24m\u001b[39m\n",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[20]:4"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "\n",
    "# Assuming generator and discriminator models are already defined along with optimizers and losses\n",
    "generator_model = generator()  # your generator model function\n",
    "discriminator_model = discriminator()  # your discriminator model function\n",
    "\n",
    "# Initialize models (if necessary, depending on model definitions)\n",
    "Flux.@functor generator_model\n",
    "Flux.@functor discriminator_model\n",
    "\n",
    "# Define the training loop\n",
    "function run_a_gan(G_train_step, G_loss, D_train_step, D_loss, num_epochs=10)\n",
    "    for epoch in 1:num_epochs\n",
    "        # Perform training steps\n",
    "        D_train_step()\n",
    "        G_train_step()\n",
    "\n",
    "        # Display samples or log progress at certain intervals\n",
    "        if epoch % 2 == 0\n",
    "            # Display or evaluate generator outputs here\n",
    "            println(\"Epoch $epoch: Displaying generated samples...\")\n",
    "            # You can add code here to generate and display images using generator_model\n",
    "        end\n",
    "\n",
    "        if epoch % 1 == 0\n",
    "            println(\"Epoch $epoch: D Loss: $(mean(D_loss)), G Loss: $(mean(G_loss))\")\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "# Setup optimizers (if not already done)\n",
    "D_opt, G_opt = gan_optimizers()  # Adjusted function to setup GAN optimizers\n",
    "\n",
    "# Define loss computations (adapt to Julia)\n",
    "D_loss, G_loss = gan2_loss(discriminator_model, generator_model)\n",
    "\n",
    "# Define training steps (using closures to capture and update the model states)\n",
    "D_train_step = () -> Flux.train!(D_loss, params(discriminator_model), data, D_opt)\n",
    "G_train_step = () -> Flux.train!(G_loss, params(generator_model), data, G_opt)\n",
    "\n",
    "# Start the training process\n",
    "run_a_gan(G_train_step, G_loss, D_train_step, D_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Results:\n",
    "Task 8 TODO: Please comment on the visual quality of the samples and how the results change over different training runs.\n",
    "\n",
    "Task 9 TODO: Re-train the first GAN architecture with random Gaussian noise instead of uniform. Please comment on the performance of the GAN and on the visual quality of the samples (during the course of the training)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
